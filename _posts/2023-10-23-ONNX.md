---
title: "ONNX(Open Neural Network Exchange)"
date: 2023-09-06 08:26:28 -0400
categories: Deep Learning
---

# ONNX(Open Neural Network Exchange)

<br>
<br>

## 0. Introduction   

<br>

<img src="https://onnx.ai/onnx/_static/onnx-horizontal-color.png">

<br>
<br>

ONNX(Open Neural Network Exchange)는 Facebook과 Microsoft가 공동으로 개발한 Open Source Project입니다. 

현재, 다양한 Deep Learning Framework가 존재하고 있으며, 각 Framework는 각기 다양한 형식으로 훈련된 Model File Format을 사용하며, 서로 호환되지 않습니니다. 

내가 구현하려는 서비스에 적합한 Pre-Trained Model이 하필 내가 사용하지 않는 Framework으로 Train되었다던지, 

적용할 시스템에서 해당 Pre-Trained Model을 사용하지 못하는 환경이라면 난감하기 그지 없겠지요.

이런 상황에서 빛을 발하는 것이 바로 ONNX입니다.  

**ONNX는 다양한 Deep Learning Framework에서 Train된 Model들을 일관성을 보장하며 서로 호환가능한 Model File Format으로 변환시켜 줍니다.**

또한, Python, C++, C# 및 Java와 같은 여러 Programming Language를 지원하고 있습니다.         

<br>
<br>
<br>

## 1. Model Conversion

<br>

ONNX의 핵심은 Computational Graphs를 보편적인 방법으로 표현하는 것입니다.

Data Graph라고도 불리는 이 Graph는 각 Model의 구성 요소 또는 Node와 이들 사이를 연결하는 Edge를 정의하고 있습니다.

현재 Neural Network 방식을 사용하는 Deep Learning Framework은 Data Graph 방식을 사용하여 Model을 표현하며,

각 Deep Learning Framework은 개발자가 Data Graph를 구성할 수 있고, 처리할 수 있는 방식을 제공합니다.

ONNX는 Data Graph의 Common Representation을 제공함으로써 개발자가 작업에 적합한 Framework를 선택할 수 있도록 합니다.   

<br>
<br>
<br>

## 2. Examples of Model Conversion

<br>

* ONNX는 현재 많이 사용되고 있는 Deep Learning Framework 대부분을 지원하고 있습니다.   

* 아래 Link에서 ONNX File Format Conversion에 대한 자세한 자료가 있습니다.
  - https://github.com/onnx/tutorials

<br>
<br>

### 2.1 Conversion to ONNX

<br>

* 각 Framework의 Model File을 ONNX File Format으로 변환하는 방법은 아래 표에서 확인할 수 있습니다.   

<br>

| Framework / Tool | Installation | Tutorial |
| --- | --- | --- |
| [Caffe](https://github.com/BVLC/caffe) | [apple/coremltools](https://github.com/apple/coremltools) and [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Example](https://github.com/onnx/onnx-docker/blob/master/onnx-ecosystem/converter_scripts/caffe_coreml_onnx.ipynb) |
| [Caffe2](https://caffe2.ai) | [part of caffe2 package](https://github.com/pytorch/pytorch/tree/master/caffe2/python/onnx) | [Example](tutorials/Caffe2OnnxExport.ipynb) |
| [Chainer](https://chainer.org/) | [chainer/onnx-chainer](https://github.com/chainer/onnx-chainer) | [Example](tutorials/ChainerOnnxExport.ipynb) |
| [Cognitive Toolkit (CNTK)](https://www.microsoft.com/en-us/cognitive-toolkit/) | [built-in](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine) | [Example](tutorials/CntkOnnxExport.ipynb) |
| [CoreML (Apple)](https://developer.apple.com/documentation/coreml) | [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Example](https://github.com/onnx/onnx-docker/blob/master/onnx-ecosystem/converter_scripts/coreml_onnx.ipynb) |
| [Keras](https://github.com/keras-team/keras) | [onnx/tensorflow-onnx](https://github.com/onnx/tensorflow-onnx) | [Example](https://github.com/onnx/tensorflow-onnx/blob/master/tutorials/keras-resnet50.ipynb) | n/a |
| [LibSVM](https://github.com/cjlin1/libsvm) | [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Example](https://github.com/onnx/onnx-docker/blob/master/onnx-ecosystem/converter_scripts/libsvm_onnx.ipynb) | n/a |
| [LightGBM](https://github.com/Microsoft/LightGBM) | [onnx/onnxmltools](https://github.com/onnx/onnxmltools) | [Example](https://github.com/onnx/onnx-docker/blob/master/onnx-ecosystem/converter_scripts/lightgbm_onnx.ipynb) | n/a |
| [MATLAB](https://www.mathworks.com/) | [Deep Learning Toolbox](https://www.mathworks.com/matlabcentral/fileexchange/67296) | [Example](https://www.mathworks.com/help/deeplearning/ref/exportonnxnetwork.html) |
| [ML.NET](https://github.com/dotnet/machinelearning/) | [built-in](https://www.nuget.org/packages/Microsoft.ML/) | [Example](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxConversionTest.cs) |
| [MXNet (Apache)](https://mxnet.incubator.apache.org/) | part of mxnet package [docs](https://mxnet.incubator.apache.org/api/python/contrib/onnx.html) [github](https://github.com/apache/incubator-mxnet/tree/master/python/mxnet/contrib/onnx) | [Example](tutorials/MXNetONNXExport.ipynb) |
| [PyTorch](https://pytorch.org/) | [part of pytorch package](https://pytorch.org/docs/master/onnx.html) | [Example1](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html), [Example2](tutorials/PytorchOnnxExport.ipynb), [export for Windows ML](tutorials/ExportModelFromPyTorchForWinML.md), [Extending support](tutorials/PytorchAddExportSupport.md) |
| [SciKit-Learn](https://scikit-learn.org/) | [onnx/sklearn-onnx](https://github.com/onnx/sklearn-onnx) | [Example](https://onnx.ai/sklearn-onnx/index.html) | n/a |
| [SINGA (Apache)](https://singa.apache.org/) - [Github](https://github.com/apache/incubator-singa/blob/master/python/singa/sonnx.py) (experimental) | [built-in](https://singa.apache.org/docs/installation/) | [Example](https://github.com/apache/incubator-singa/tree/master/examples/onnx) |
| [TensorFlow](https://www.tensorflow.org/) | [onnx/tensorflow-onnx](https://github.com/onnx/tensorflow-onnx) | [Examples](https://github.com/onnx/tutorials/blob/master/tutorials/TensorflowToOnnx-1.ipynb) |
   

<br>
<br>

### 2.2 Load from ONNX File

<br>

* ONNX File로 되어 있는 Model을 각 Framework에서 읽어서 사용하는 방법은 아래 표에서 확인할 수 있습니다.   

<br>

| Framework / Tool | Installation | Tutorial |
| --- | --- | --- |
| [Caffe2](https://caffe2.ai) | [Caffe2](https://github.com/pytorch/pytorch/tree/master/caffe2/python/onnx) | [Example](tutorials/OnnxCaffe2Import.ipynb) |
| [Cognitive Toolkit (CNTK)](https://www.microsoft.com/en-us/cognitive-toolkit/) | [built-in](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine) | [Example](tutorials/OnnxCntkImport.ipynb)|
| [CoreML (Apple)](https://developer.apple.com/documentation/coreml) | [onnx/onnx-coreml](https://github.com/onnx/onnx-coreml) | [Example](tutorials/OnnxCoremlImport.ipynb)|
| [MATLAB](https://www.mathworks.com/) | [Deep Learning Toolbox Converter](https://www.mathworks.com/matlabcentral/fileexchange/67296) | [Documentation and Examples](https://www.mathworks.com/help/deeplearning/ref/importonnxnetwork.html) |
| [Menoh](https://github.com/pfnet-research/menoh) | [Github Packages](https://github.com/pfnet-research/menoh/releases) or from [Nuget](https://www.nuget.org/packages/Menoh/) | [Example](tutorials/OnnxMenohHaskellImport.ipynb) |
| [ML.NET](https://github.com/dotnet/machinelearning/) | [Microsoft.ML Nuget Package](https://www.nuget.org/packages/Microsoft.ML/) | [Example](https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.OnnxTransformerTest/OnnxTransformTests.cs) |
| [MXNet (Apache)](https://mxnet.incubator.apache.org/) - [Github](https://github.com/apache/incubator-mxnet/tree/master/python/mxnet/contrib/onnx) | [MXNet](https://mxnet.incubator.apache.org/versions/master/install/index.html?platform=Linux&language=Python&processor=CPU) |  [API](https://mxnet.incubator.apache.org/api/python/contrib/onnx.html) <br>[Example](tutorials/OnnxMxnetImport.ipynb) |
[ONNX Runtime](https://github.com/microsoft/onnxruntime) | See [onnxruntime.ai](https://onnxruntime.ai)| [Documentation](https://onnxruntime.ai/docs/) |
| [SINGA (Apache)](https://singa.apache.org/) - [Github](https://github.com/apache/incubator-singa/blob/master/python/singa/sonnx.py) [experimental]| [built-in](https://singa.apache.org/docs/installation/) | [Example](https://github.com/apache/incubator-singa/tree/master/examples/onnx) |
| [Tensorflow](https://www.tensorflow.org/) | [onnx-tensorflow](https://github.com/onnx/onnx-tensorflow) | [Example](tutorials/OnnxTensorflowImport.ipynb)|
| [TensorRT](https://developer.nvidia.com/tensorrt) | [onnx-tensorrt](https://github.com/onnx/onnx-tensorrt) | [Example](https://github.com/onnx/onnx-tensorrt/blob/master/README.md) |
| [Windows ML](https://docs.microsoft.com/en-us/windows/ai/windows-ml) | Pre-installed on [Windows 10](https://docs.microsoft.com/en-us/windows/ai/release-notes) | [API](https://docs.microsoft.com/en-us/windows/ai/api-reference) <br>Tutorials - [C++ Desktop App](https://docs.microsoft.com/en-us/windows/ai/get-started-desktop), [C# UWP App](https://docs.microsoft.com/en-us/windows/ai/get-started-uwp) <br> [Examples](https://docs.microsoft.com/en-us/windows/ai/tools-and-samples) |
| [Vespa.ai](https://vespa.ai) | [Vespa Getting Started Guide](https://docs.vespa.ai/en/getting-started.html) | [Real Time ONNX Inference](https://github.com/vespa-engine/sample-apps/tree/master/model-inference) <br>Distributed Real Time ONNX Inference for [Search and Passage Ranking](https://github.com/vespa-engine/sample-apps/blob/master/msmarco-ranking/passage-ranking-README.md)|   


<br>
<br>
<br>

## 3. Usage Scenario

<br>

* 아래 Link에서 ONNX를 사용하는 다양한 Usage를 보여주고 있습니다.
  - https://github.com/onnx/tutorials#end-to-end-tutorials

<br>

* 제 생각에는 ONNX를 사용해서 얻을 수 있는 가장 큰 이점은 바로 ONNX Runtime을 사용하는 것이 아닌가 하는데요, 이에 관해서는 다른 Post로 좀 더 알아보도록 하겠습니다.   

* 이번 Post에서는 ONNX에 대해서 간단하게 알아보았습니다.
* ONNX의 가장 큰 장점은 Framework간 Model File의 자유로운 변환이며, 다음으로는 ONNX Runtime을 사용할 수 있다는 것이 아닐까 합니다.
* 글 읽어 주셔서 감사하고, 조금이나마 도움이 되었기를 바랍니다.

<br>
