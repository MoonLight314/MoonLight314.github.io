---
title: "CNN( Convolutional Neural Network )"
date: 2020-03-03 08:26:28 -0400
categories: Study CNN
---
# CNN ( Convolutional Neural Network )
<br>
<br>
<br>
<br>

## 순서

### 1. CNN Introduction
### 2. Terminology
### 3. Basic Codes & Exercise
### 4 Pre-Trained Models

<br>
<br>
<br>
<br>   
<br>
<br>
<br>
<br>
<br>
<br>
<br>


## 1. CNN Introduction

### 1.1. 시각적 인식
 * 시각적 인식은 어떻게 이루어 지는가 ?

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_00.png">
</p>

•  고양이의 머리에 전극을 연결 후, 시각 자극에 대한 뇌의 신경들이 어떻게 반응하는지 관찰  
•  관찰 결과
  - 특정 자극에만 반응하는 특정 뉴런 존재
  - **자극은 여러 과정을 거치면서 단순한 형태에서 점점 복잡한 형태( 추상적 )로 지각된다.**  
      → CNN 의 이론적 토대

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_01.png">
</p>

<br>
<br>
<br>
<br>

### 1.2. CNN( Convolution Neural Network )
 * Deep Neural Network의 한 종류로써, 하나 또는 여러 개의 Convolution Layer와 Pooling Layer, Fully Connected Layer등으로 구성된 **Image 분석에 특화된 신경망**

 * Convolution의 수학적 정의  
  - 수학적으로 Convolution이란 두 함수를 이용해 다른 함수에 의해 해당 함수의 모양이 변화되는 새로운 함수를 생성하는 것  
  - 기존 Image Data에 어떤 연산을 하여 새로운 Data를 만든다.

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_02.png">
</p>


<br>
<br>
<br>
<br>
<br>

### 1.3. Fully Connected vs CNN
 * FC( Fully Connected ) Layer ?
   - FC란 다음과 같이 개별적인 값을 Network의 Input으로 사용하는 Layer를 말한다.

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_03.png">
</p>

* **FC vs CNN**
  - Fully Connected Layer로 구성된 인공 신경망의 입력 데이터는 1차원(배열) 형태가 되어야 한다.
  - 한 장의 컬러 사진은 3차원 데이터(Height , Width , Color )로 구성되어 있다. 
  - 사진 데이터를 Fully Connected 신경망을 학습시켜야 할 경우에, 3차원 사진 데이터를 1차원으로 평면화시켜야 한다.
  - 사진 데이터를 평면화 시키는 과정에서 공간 정보가 손실될 수밖에 없다. 
  - 결과적으로 Image 공간 정보 유실로 인한 정보 부족으로 인공 신경망이 특징을 추출 및 학습이 비효율, 정확도를 높이는데 한계가 있다. 
  - Image의 공간 정보를 유지한 상태로 학습이 가능한 모델이 바로 CNN(Convolutional Neural Network)입니다.
  
<br>
<br>
<br>
<br>
<br>

### 1.4. CNN의 특징
 * 각 Layer의 입출력 데이터의 형상 유지
 * Image의 공간 정보를 유지하면서 인접 Image와의 특징을 효과적으로 인식
 * 복수의 Filter로 Image 의 특징 추출 및 학습
 * 추출한 Image 의 특징을 모으고 강화하는 Pooling Layer
 * Filter를 공유 Parameter로 사용하기 때문에, 일반 Neural Net.과 비교하여 학습 Parameter가 매우 적음
 
<br>
<br>
<br>
<br>
<br>

### 1.5. Simple CNN Example
  * 아래 그림은 CNN의 가장 전형적인 구조를 보여줍니다.

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_04.png">
</p>


<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

## 2. Terminology

<br>
<br>
<br>
<br>
<br>  

### 2.1. Terminology
 * Convolution
 * Channel
 * **Filter ( Kernel )**
 * **Stride**
 * **Padding**
 * Feature Map( Activation Map )
 * **Pooling Layer**
 
 <br>
<br>
<br>
<br>
<br>  

### 2.2. Channel
 * 컬러 Image는 3개의 Channel로 구성
 * 흑백 Image는 1개의 Channel

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_05.png">
</p>
 
 <br>
<br>
<br>
<br>
<br>  

### 2.3. Filter( Kernel )
 * Filter는 Image의 특징을 찾아내기 위한 공용 Parameter
 * Filter는 일반적으로 (4, 4)이나 (3, 3)과 같은 정사각 행렬로 정의
 * 입력 데이터를 지정된 간격(Stride)으로 순회하며 Channel별로 합성곱을 하고 모든 Channel(컬러의 경우 3개)의 합성곱의 합을 Feature Map생성
 
 <br>
<br>
<br>
<br>
<br> 

### 2.4. Application of Filter(Kernel)
 * Image의 **기하학적 정보**를 추출한다

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_06.png">
</p>

 <br>
<br>
<br>
<br>
<br> 

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_07.png">
</p>

 <br>
<br>
<br>
<br>
<br> 

### 2.5. Stride
 * 한번에 Filter가 **움직이는 거리**

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_08.png">
</p>

 <br>
<br>
<br>
<br>
<br> 

### 2.6. Padding
 * Filter를 적용할 수록 Image Size는 작아지고, 정보가 사라짐
 * 모서리 부분의 Data를 살리고자 할 때
 * 보통 0으로 채운다
 * Size를 조절하는 기능이 외에, 외각을 “0”값으로 둘러싸는 특징으로 부터 인공 신경망이 Image의 외각을 인식하는 학습 효과도 있음

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_09.png">
</p>

 <br>
<br>
<br>
<br>
<br> 

### 2.7. Pooling Layer
 * Pooling Layer는 Conv. Layer의 출력 데이터를 입력으로 받아서 출력 데이터(Activation Map)의 크기를 줄이거나 **특정 데이터를 강조**하는 용도로 사용
 * Pooling Layer를 처리하는 방법으로는 Max Pooling과 Average Pooning, Min Pooling이 있음
 * 정사각 행렬의 특정 영역 안에 값의 최댓값을 모으거나 특정 영역의 평균을 구하는 방식으로 동작

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_10.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### 2.8. CNN Training Process
 * CNN Network이 Image를 학습하는 과정을 시각화한 자료입니다.
 * 아래 Link를 참고하세요.

[![Video Label](http://img.youtube.com/vi/f0t-OCG79-U/0.jpg)](https://youtu.be/f0t-OCG79-U)

<br>
<br>
<br>
<br>
<br> 

### 2.9. General Architecture of CNN
 * CNN은 Convolution Layer와 Max Pooling Layer를 반복적으로 stack을 쌓는 특징 추출(Feature Extraction) 부분과 Fully Connected Layer를 구성하고 마지막 출력층에 Softmax를 적용한 분류 부분으로 나뉨

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_11.png">
</p>

<br>
<br>
<br>
<br>
<br> 
<br>
<br>
<br>
<br>
<br> 


## 3. Basic Codes

<br>
<br>
<br>
<br>
<br> 

### 3.1. Basic Tensorflow Code
 * 다음의 Example Code는 일반적인 Tensorflow Code를 이용한 CNN을 구현한 것입니다.
 * 출처는 김훈님의 Deep Learning 강의입니다.

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_12.png">
  <img src="/assets/CNN_Doc_Img/pic_13.png">
  <img src="/assets/CNN_Doc_Img/pic_14.png">
  <img src="/assets/CNN_Doc_Img/pic_15.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### 3.2. Basic Keras Code
 * 다음의 Example Code는 일반적인 Keras Code를 이용한 CNN을 구현한 것입니다.
 * Tensorflow Code보다 훨씬 간결하고 직관적이다.

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_16.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### 3.3. General Process of CNN Model Training
 * CNN Model Training 과정을 재밌게 시각화한 자료가 있어서 공유드립니다.

[![Video Label](http://img.youtube.com/vi/RNnKtNrsrmg/0.jpg)](https://youtu.be/RNnKtNrsrmg)

<br>
<br>
<br>
<br>
<br> 
<br>
<br>
<br>
<br>
<br> 



## 4. Pre-Trained Models & Exercise

<br>
<br>
<br>
<br>
<br> 

### 4.1. Image Dataset
 * Image Train에 사용할 수 있도록 공개된 Training용 Image Data Set이 많이 있습니다.
 * CNN Model에 관련된 자료를 보시다 보면, 자주 등장하는 Dataset에 대한 정보를 조사하였습니다. 

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_17.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### 4.2. Pre-trained CNN Model in Keras
 * Keras에서 제공하는 Pre-Trained Model의 종류는 다음과 같습니다.
 * Top-1 Accuracy : Model이 분류한 결과중 가장 높은 확률 1개가 정답일 확률
 * Top-5 Accuracy : Model이 분류한 결과중 가장 높은 확률 5개 중에 정답이 있을 확률

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_18.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### 4.3. InceptionV3
 * 자주 접할 수 있는 Pre-Trained Model중 하나인 InceptionV3의 구조입니다.

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_19.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### 4.4. VGG16

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_20.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### 4.5. ResNet
 * Microsoft 북경 연구소 개발 ( Kaiming He , Xiangyu Zhang , Shaoqing Ren , Jian Sun )
 * 논문 : https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf
<br> 
### **층을 깊게 하면 무조건 성능이 좋아질까 ?**
<br> 
<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_21.png">
</p>

<br> 

* Convolution Layer & Fully Connected Layer를 추가해 56 Layers & 20 Layers Model로 Test 진행
### **결과에서 보듯이 무조건 망을 깊게 하는 것이 능사가 아니다.**

<br>
<br>
<br>
<br>
<br> 

### Degradation

* Neural Network은 Weight / Bias를 확률적 경사 하강법(stochastic gradient descent)을 통해 Update
* Gradient를 통해 Weight를 Update할 때, **Gradient가 Explode or Vanishing 해버리는 경우 발생**
* https://dnddnjs.github.io/cifar10/2018/10/09/resnet/

* **이를 개선하기 위해서**
  - Xavier initialization / He initialization
  - Batch Normalization (Sergey Ioffe & Christian Szegedy )
    * Neural Network가 학습하기 어려운 이유를 internal covariate shift.  
      ( Internal Covariate Shift : Neural Network가 학습하면서 각 층의 입력 분포가 계속 변하는 현상 )
    * Mini-batch마다 각 층의 Input을 Normalization하는 방법으로 어느정도 해결했다. 
    * Batch normalization을 사용하면 initialization을 크게 신경쓰지 않아도 된다. 
    * Optimizer의 learning rate를 이전보다 더 높일 수 있다
    * 일종의 Regularization 역할도 하기 때문에 Dropout을 사용하지 않아도 학습이 잘 되는 특성이 있다. 
    * 이 때부터 많은 neural Network에서 dropout을 사용하지 않기 시작했다.    

   * Highway Network
      - Degradation 문제를 개선하기 위해 제안된 Network 구조. LSTM에 영감을 받음

• **ResNet도 Highway Network과 마찬가지로 Degradation 문제를 개선하기 위해 제안된 Network 구조**  
  ( https://dnddnjs.github.io/cifar10/2018/10/09/resnet/ )

* 기존 CNN은 Input X를 Target에 Mapping 시키는 H(x)를 찾는 것이 목적 ( Direct Mapping )
* Residual은 일종의 오차.
* Residual Learning은 Input으로부터 얼마만큼 달라져야 하는지를 학습. 

* H(x)가 학습해야하는 Mapping이라면 H(x)를 H(x) = F(x) + x로 새롭게 정의. 
* Neural Network 학습 목표를 H(x) 학습에서 F(x) 학습으로 변경

<br>
<br>
<br>
<br>
<br> 

### Shortcut Connection
  * 몇 개의 layer를 건너뛰는 것(Skip)
  * ResNet에서 Shortcut Connection은 2개의 Layer를 건너뛴다. 
  * Layer에 들어오는 입력이 Shortcut Connection을 통해서 건너뛰면 Layer를 지난 출력과 Element-Wise Addition 한다.

<p align="center">
  <img src="/assets/CNN_Doc_Img/pic_22.png">
</p>

<br>
<br>
<br>
<br>
<br> 

### ResNet 구조   

![title](https://miro.medium.com/max/3294/1*HLwBD8R8PIqJSiMHJaj6fQ.png)

<br>
<br>
<br>
<br>
<br> 
