---
title: "Using TFReocrd File"
date: 2021-05-14 08:26:28 -0400
categories: Deep Learning
---

### Using TFReocrd File



* 이전 Post에서 TFRecord File Format을 만드는 방법에 대해서 알아보았습니다.


* 이번 Post에서는 지난 번에 작성한 TFRecord Dataset으로 Image Classification을 해보겠습니다.


* TFRecord는 Tensorflow와 함께 사용할 때 최고의 성능을 보여줍니다. 그래서, 가능하면 모든 Code들은 Tensorflow에서 제공하는 Function들을 사용해서 작성해 보도록 하겠습니다.

   

   

   

   

   

   

## 0. Prepare   

* 필요한 Module을 Load합니다.   


```python
import tensorflow as tf
from tqdm import tqdm
from sklearn.model_selection import train_test_split
```

   

   

* Batch Size와 Prefetch할 Size를 미리 정의합니다.   


```python
class CFG:
    BATCH_SIZE = 32
    BUFFER_SIZE = 500
```

   

   

   

   

* 추후에 map에 적용하기 위해서 TFRecord File들의 Full Path를 구해놓습니다.


```python
Cat_Fearue_File_List = tf.io.gfile.listdir("./PetImages/Cat/TFRecord")
Cat_Fearue_File_List = list(map(lambda x:"./PetImages/Cat/TFRecord/" + x, Cat_Fearue_File_List))

print(len(Cat_Fearue_File_List))
Cat_Fearue_File_List[:10]
```

    12427
    




    ['./PetImages/Cat/TFRecord/0.tfrecord',
     './PetImages/Cat/TFRecord/1.tfrecord',
     './PetImages/Cat/TFRecord/10.tfrecord',
     './PetImages/Cat/TFRecord/100.tfrecord',
     './PetImages/Cat/TFRecord/1000.tfrecord',
     './PetImages/Cat/TFRecord/10000.tfrecord',
     './PetImages/Cat/TFRecord/10001.tfrecord',
     './PetImages/Cat/TFRecord/10002.tfrecord',
     './PetImages/Cat/TFRecord/10003.tfrecord',
     './PetImages/Cat/TFRecord/10004.tfrecord']



   

   

   

   


```python
Dog_Fearue_File_List = tf.io.gfile.listdir("./PetImages/Dog/TFRecord")
Dog_Fearue_File_List = list(map(lambda x:"./PetImages/Dog/TFRecord/" + x, Dog_Fearue_File_List))

print(len(Dog_Fearue_File_List))
Dog_Fearue_File_List[:10]
```

    12397
    




    ['./PetImages/Dog/TFRecord/0.tfrecord',
     './PetImages/Dog/TFRecord/1.tfrecord',
     './PetImages/Dog/TFRecord/10.tfrecord',
     './PetImages/Dog/TFRecord/100.tfrecord',
     './PetImages/Dog/TFRecord/1000.tfrecord',
     './PetImages/Dog/TFRecord/10000.tfrecord',
     './PetImages/Dog/TFRecord/10001.tfrecord',
     './PetImages/Dog/TFRecord/10002.tfrecord',
     './PetImages/Dog/TFRecord/10003.tfrecord',
     './PetImages/Dog/TFRecord/10004.tfrecord']



   

   

   

   

## 1. Train & Validation Set Split

* Train시에 사용할 Train / Val. Set을 분리하겠습니다.


* Cat / Dog 별로 동일한 8:2로 나누겠습니다.

   


```python
Cat_Train_File_List, Cat_Val_File_List = train_test_split(Cat_Fearue_File_List, test_size=0.2, random_state=123)
```


```python
print("Cat Train : ",len(Cat_Train_File_List) , "Cat Val. : ",len(Cat_Val_File_List))
```

    Cat Train :  9941 Cat Val. :  2486
    

   

   

   


```python
Dog_Train_File_List, Dog_Val_File_List = train_test_split(Dog_Fearue_File_List, test_size=0.2, random_state=123)
```


```python
print("Dog Train : ",len(Dog_Train_File_List) , "Dog Val. : ",len(Dog_Val_File_List))
```

    Dog Train :  9917 Dog Val. :  2480
    

   

   

   

* Cat / Dog의 Train File List와 Val. File List를 합칩니다.   


```python
Train_Feature_File_List = Cat_Train_File_List + Dog_Train_File_List
```


```python
Val_Feature_File_List = Cat_Val_File_List + Dog_Val_File_List
```


```python
print(len(Train_Feature_File_List) , len(Val_Feature_File_List) )
```

    19858 4966
    

   

   

* 잘 섞어줍니다.   


```python
Train_Feature_File_List = tf.random.shuffle(Train_Feature_File_List)
```


```python
Train_Feature_File_List
```




    <tf.Tensor: shape=(19858,), dtype=string, numpy=
    array([b'./PetImages/Dog/TFRecord/10425.tfrecord',
           b'./PetImages/Cat/TFRecord/3119.tfrecord',
           b'./PetImages/Cat/TFRecord/5364.tfrecord', ...,
           b'./PetImages/Dog/TFRecord/9267.tfrecord',
           b'./PetImages/Dog/TFRecord/12042.tfrecord',
           b'./PetImages/Dog/TFRecord/551.tfrecord'], dtype=object)>




```python
Val_Feature_File_List = tf.random.shuffle(Val_Feature_File_List)
```


```python
Val_Feature_File_List
```




    <tf.Tensor: shape=(4966,), dtype=string, numpy=
    array([b'./PetImages/Dog/TFRecord/4587.tfrecord',
           b'./PetImages/Cat/TFRecord/387.tfrecord',
           b'./PetImages/Cat/TFRecord/5345.tfrecord', ...,
           b'./PetImages/Dog/TFRecord/2247.tfrecord',
           b'./PetImages/Dog/TFRecord/12447.tfrecord',
           b'./PetImages/Cat/TFRecord/9419.tfrecord'], dtype=object)>



   

   

   

   

   

   

   

   

## 2. Making Dataset   

* 이제 TFRecord File을 읽어서 Dataset을 만들도록 하겠습니다.


* 전체적인 순서는
  - TFRecord File들의 Full Path를 가지고 Dataset 생성
  - TFRecord File을 읽어서 Contents를 읽어오는 Map Function 작성 / 적용
  - Dataset에 shuffle / batch / prefetch 적용
  - Train에 적용
  
  
* 하나씩 알아보겠습니다.  

   

   

   

### 2.1. Map Function

* TFRecord File의 내용을 Decoding하는 Function입니다.


* **def map_fn(serialized_example):**
  - Parameter로 넘어오는 serialized_example는 TFRecord File의 Full Path입니다.
  - 아래쪽에 TFRecordDataset을 이용해서 Dataset을 만들때 Parameter로 사용하는 값이 serialized_example로 넘어오는 것입니다.
  
  
  
* **feature = {**
        'Feature': tf.io.FixedLenFeature([49*1280], tf.float32),
        'Label': tf.io.FixedLenFeature([1], tf.int64)
    **}**
    
   - 우리가 읽을 TFRecord File의 구조를 정의하는 부분입니다.
   - 'Feature'라는 Data는 Float형, 길이가 62720이며, 'Label'이라는 Data는 Type이 Int형, 길이가 1이라는 뜻입니다.
   - 가만히 생각해 보면, 우리가 다른 사람이 작성한 TFRecord File을 읽어야 하는 경우에는 이러한 구조를 모르면 Decoding할 수가 없습니다.
   - 즉, **TFRecord Format으로 Dataset을 배포할 때는 반드시 이런 구조 정보를 함께 알려주어야 하는 것입니다.**



* **example = tf.io.parse_single_example(serialized_example, feature)**
  - 실제 File을 읽어서 위에서 정의한 구조대로 Decoding하는 부분입니다.
  
  
* **example['Feature'] = tf.reshape( example['Feature'] , (7,7,1280) )**
  - 우리가 TFRecord File을 저장할 때, Shape을 Flatten했기 때문에, 원래 모양대로 원상 복구합니다.
  
  
* **tf.squeeze( tf.one_hot(example['Label'] , depth=2) )**
  - Label은 Cat인 경우 0, Dog인 경우에 1입니다.
  - One Hot 형식으로 변경하는 부분입니다.


```python
def map_fn(serialized_example):

    feature = {
        'Feature': tf.io.FixedLenFeature([49*1280], tf.float32),
        'Label': tf.io.FixedLenFeature([1], tf.int64)
    }
    
    example = tf.io.parse_single_example(serialized_example, feature)
    
    example['Feature'] = tf.reshape( example['Feature'] , (7,7,1280) )
    
    return example['Feature'], tf.squeeze( tf.one_hot(example['Label'] , depth=2) )
```

   

   

   

### 2.2. Define Dataset

* 우리는 TFRecord File List가 있기 때문에, Dataset 생성에 tf.data.TFRecordDataset을 사용하도록 하겠습니다.


```python
Train_Dataset = tf.data.TFRecordDataset( Train_Feature_File_List )
Val_Dataset = tf.data.TFRecordDataset( Val_Feature_File_List )
```


```python
Train_Dataset
```




    <TFRecordDatasetV2 shapes: (), types: tf.string>




```python
Val_Dataset
```




    <TFRecordDatasetV2 shapes: (), types: tf.string>



   

   

   

* Dataset도 만들었고, Dataset에 적용할 Map Function도 만들었으니 이제 shuffle / batch / prefetch를 적용합니다.   


```python
Train_Dataset = Train_Dataset.map(map_fn , 
                      num_parallel_calls=tf.data.experimental.AUTOTUNE)

Train_Dataset = Train_Dataset.shuffle(CFG.BUFFER_SIZE).batch(CFG.BATCH_SIZE)
Train_Dataset = Train_Dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
```


```python
Val_Dataset = Val_Dataset.map(map_fn , 
                      num_parallel_calls=tf.data.experimental.AUTOTUNE)

Val_Dataset = Val_Dataset.shuffle(CFG.BUFFER_SIZE).batch(CFG.BATCH_SIZE)
Val_Dataset = Val_Dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
```

   

   

   

* 제대로 읽는지 하나만 살펴볼까요?   


```python
for batch in Train_Dataset.take(1):
    batch
```


```python
print(batch)
batch[1].numpy()
```

    (<tf.Tensor: shape=(32, 7, 7, 1280), dtype=float32, numpy=
    array([[[[-1.30283579e-01, -1.79280803e-01, -2.73918390e-01, ...,
              -2.35235289e-01, -2.51564652e-01, -1.24651089e-01],
             [-2.23974511e-01, -2.69972891e-01, -2.78214544e-01, ...,
              -1.61265686e-01, -2.63588488e-01,  4.82403219e-01],
             [-9.15986970e-02, -7.91421384e-02, -2.09058121e-01, ...,
              -2.46901169e-01, -2.35181734e-01, -2.75620580e-01],
             ...,
             [-4.28934097e-02, -3.80189456e-02, -9.37430859e-02, ...,
              -2.70000398e-01, -2.56699502e-01,  3.71812642e-01],
             [-3.37041589e-03,  2.37213349e+00, -2.73799729e-02, ...,
              -2.78330237e-01, -2.63371170e-01, -2.72408187e-01],
             [-2.69764900e-01, -9.48898420e-02, -6.93319291e-02, ...,
              -2.59258837e-01, -2.78016418e-01, -2.23277569e-01]],
    
            [[-2.40731761e-01, -1.49252594e-01, -1.29014462e-01, ...,
              -3.48842107e-02, -2.78116941e-01,  1.21828353e+00],
             [-2.78438926e-01,  5.36722839e-01, -1.36655658e-01, ...,
              -6.23840746e-03, -2.26522133e-01,  1.85954738e+00],
             [-6.25507459e-02, -1.00828111e-01, -1.55045748e-01, ...,
              -4.72838171e-02, -1.98967606e-01, -2.27459908e-01],
             ...,
             [-4.31086839e-04,  2.16324544e+00, -1.06345741e-02, ...,
              -3.63434367e-02, -3.13317887e-02,  9.24772203e-01],
             [-1.53233509e-06,  1.35951967e+01, -7.76352419e-04, ...,
              -4.41170437e-03, -2.31151477e-01, -2.63853192e-01],
             [-6.46062661e-03,  4.92377949e+00, -1.39266048e-02, ...,
              -5.87231778e-02,  1.09022892e+00, -2.71575540e-01]],
    
            [[-1.42593503e-01,  3.51380378e-01, -2.29087830e-01, ...,
              -9.77664907e-03, -2.43833497e-01,  6.59770250e-01],
             [-6.03562184e-02,  2.67279983e+00, -8.22568163e-02, ...,
              -3.87481693e-03, -3.45014818e-02,  2.45907426e+00],
             [-6.38377480e-03,  4.15273046e+00, -1.50325801e-02, ...,
              -8.94669294e-02, -1.27345668e-02, -2.78422236e-01],
             ...,
             [-3.85519373e-03, -1.10767812e-01, -3.39450780e-03, ...,
              -1.03545524e-02, -8.26057419e-03,  1.70724523e+00],
             [-5.78504521e-04,  6.60518837e+00, -2.84841983e-04, ...,
              -3.46982223e-03, -2.71046907e-02, -9.67810899e-02],
             [-5.40567897e-02, -2.77622372e-01, -3.78229097e-02, ...,
              -6.76211938e-02, -2.77685404e-01, -2.49596104e-01]],
    
            ...,
    
            [[-9.94914696e-02, -1.36975139e-01, -5.02639115e-02, ...,
              -6.02099746e-02, -2.37369090e-02, -2.65794516e-01],
             [-3.45942155e-02, -3.48704234e-02, -3.77649032e-02, ...,
              -1.16001353e-01, -6.85767084e-02, -2.39090085e-01],
             [-1.72518510e-02, -4.55257967e-02, -4.35404219e-02, ...,
              -2.05560416e-01, -2.38478035e-01, -2.41672918e-01],
             ...,
             [-1.37439100e-02, -1.04076974e-02, -8.73748772e-03, ...,
              -7.20536802e-03, -9.39005762e-02, -2.62033850e-01],
             [-7.13470280e-02, -9.91088897e-03, -1.97724868e-02, ...,
              -3.99898030e-02, -1.19407102e-01, -2.30754659e-01],
             [-7.85152763e-02, -6.60116822e-02, -1.38968870e-01, ...,
              -2.72400439e-01, -2.54192859e-01, -1.09282821e-01]],
    
            [[-1.76074564e-01, -9.39058959e-02, -1.25399411e-01, ...,
              -4.02487628e-02, -3.30523252e-02, -2.45824859e-01],
             [-1.12892844e-01, -5.07779680e-02, -1.16894685e-01, ...,
              -1.40380353e-01, -1.00670680e-01, -2.77867734e-01],
             [-5.11221178e-02, -4.57501337e-02, -1.21301681e-01, ...,
              -2.52175003e-01, -2.30490252e-01, -1.06910519e-01],
             ...,
             [-7.98536763e-02, -2.39567868e-02, -3.00220847e-02, ...,
              -1.95437055e-02, -1.01633057e-01, -1.21321648e-01],
             [-2.11759537e-01, -2.61094701e-02, -4.45100069e-02, ...,
              -2.98382565e-02, -8.85921568e-02, -1.45456001e-01],
             [-1.15490787e-01, -5.19479141e-02, -1.32867336e-01, ...,
              -1.81280360e-01, -2.05838978e-01, -2.41050556e-01]],
    
            [[-1.78215072e-01, -5.62559888e-02, -1.57253504e-01, ...,
              -9.03731063e-02, -6.98940903e-02, -2.49010473e-01],
             [-1.20267414e-01, -3.23394574e-02, -1.51221678e-01, ...,
              -1.47827640e-01, -1.45642743e-01, -1.48217440e-01],
             [-9.13164914e-02, -2.61738785e-02, -1.50756165e-01, ...,
              -2.08552867e-01, -1.78551063e-01, -1.64105788e-01],
             ...,
             [-1.45338163e-01, -5.79812378e-02, -1.45262361e-01, ...,
              -8.04058015e-02, -7.63092265e-02, -2.67663211e-01],
             [-1.45364776e-01, -3.51961665e-02, -1.23100735e-01, ...,
              -7.06390962e-02, -7.20034391e-02, -2.57086247e-01],
             [-1.23126574e-01, -5.48275374e-02, -1.70503005e-01, ...,
              -1.39711812e-01, -1.39835358e-01, -1.72645301e-01]]],
    
    
           [[[-2.62581289e-01, -1.06273152e-01,  2.19422787e-01, ...,
               4.43883628e-01, -2.66581774e-01, -1.75360392e-03],
             [-2.31495291e-01, -8.89109150e-02,  2.94292480e-01, ...,
               8.11607480e-01, -1.39667720e-01, -2.76840270e-01],
             [-1.49130583e-01, -5.69357276e-02,  1.29539728e+00, ...,
              -1.37161940e-01, -2.20683336e-01,  1.29058704e-01],
             ...,
             [-2.36960903e-01, -2.63230026e-01,  3.18346113e-01, ...,
              -5.69689237e-02, -2.35937640e-01,  3.10738397e+00],
             [-2.32361495e-01, -2.76459664e-01,  4.79288042e-01, ...,
              -1.73070282e-02, -2.47664973e-01,  1.65427053e+00],
             [-2.57041872e-01, -1.07943572e-01,  1.00945461e+00, ...,
              -1.38169611e-02, -3.21869366e-02, -7.52904564e-02]],
    
            [[-2.71945983e-01, -2.28862930e-02,  4.24007207e-01, ...,
               7.46094644e-01, -1.00065768e-01, -2.43476361e-01],
             [-1.83762714e-01, -2.29329765e-02,  1.29824924e+00, ...,
               1.66978550e+00, -1.85843557e-02, -1.27816722e-01],
             [ 2.54734218e-01, -5.49371280e-02,  1.39791620e+00, ...,
               5.22007644e-01, -9.75904018e-02, -2.24525049e-01],
             ...,
             [-2.17218965e-01, -1.77255601e-01, -1.95991591e-01, ...,
              -8.16302747e-03, -2.78406620e-01,  1.48708463e+00],
             [-1.02170147e-01,  1.94365587e-02, -2.75816292e-01, ...,
              -3.41529056e-04, -1.42046377e-01, -3.11066788e-02],
             [-2.78320581e-01, -1.07067890e-01,  8.30221593e-01, ...,
              -2.11770460e-03, -7.01141730e-03, -1.56333447e-01]],
    
            [[ 1.47607458e+00, -9.26607624e-02,  1.06849480e+00, ...,
              -2.70972252e-01, -3.43550965e-02, -2.76625603e-01],
             [ 1.76792562e+00, -1.15878239e-01,  2.08287311e+00, ...,
              -1.48634940e-01, -7.62300566e-03, -2.73858786e-01],
             [ 3.60432029e+00, -9.59366038e-02,  1.47837675e+00, ...,
              -7.39343688e-02, -6.62507582e-03, -1.27088144e-01],
             ...,
             [-2.49655604e-01, -2.65452206e-01, -1.30516157e-01, ...,
              -5.40549518e-04, -1.66551229e-02, -2.63659209e-01],
             [-1.84890598e-01,  2.22761229e-01, -1.20039783e-01, ...,
              -1.22913552e-04, -2.03891601e-02, -1.76161796e-01],
             [ 1.74382493e-01, -8.44135210e-02, -1.07172772e-01, ...,
              -7.92130828e-03, -2.25175526e-02, -9.16120633e-02]],
    
            ...,
    
            [[ 2.56980881e-02, -2.64417529e-01, -7.57955462e-02, ...,
              -2.32537746e-01, -4.02390882e-02, -1.72088593e-01],
             [ 1.05733311e+00, -9.01504830e-02, -5.76986820e-02, ...,
              -5.60242459e-02, -6.67797253e-02, -2.77394146e-01],
             [ 3.86115551e+00, -8.24033394e-02, -1.26427412e-01, ...,
              -8.45960006e-02, -9.56042185e-02, -1.78068921e-01],
             ...,
             [-8.79599303e-02, -2.65007019e-01, -1.35751188e-01, ...,
              -3.27893831e-02, -3.68003314e-03, -2.35982671e-01],
             [-9.24290046e-02,  2.93453466e-02, -2.69800723e-01, ...,
              -8.69006105e-03, -6.65485440e-03, -2.76941597e-01],
             [-2.76027083e-01, -2.20292866e-01,  8.42309743e-02, ...,
              -9.98783782e-02, -9.09883454e-02, -2.31080383e-01]],
    
            [[-3.50414254e-02, -2.36933559e-01, -8.07484686e-02, ...,
               2.21329778e-01, -2.00298876e-01, -1.99695706e-01],
             [-2.17061609e-01, -1.96686715e-01, -6.91138729e-02, ...,
               3.87674391e-01, -2.62121707e-01, -2.08735511e-01],
             [ 1.18299782e+00, -1.66440129e-01, -9.84654501e-02, ...,
               3.19867462e-01, -2.77710170e-01, -2.60284096e-01],
             ...,
             [-2.26965144e-01, -1.41092926e-01, -2.78455555e-01, ...,
              -2.32789531e-01, -1.31342083e-01, -2.69369245e-01],
             [-2.45815247e-01, -1.74222291e-01, -1.49580047e-01, ...,
              -1.85273588e-01, -9.98403430e-02,  1.52284712e-01],
             [-6.92428797e-02, -2.40116328e-01,  3.42393279e-01, ...,
              -1.59982413e-01, -1.52332932e-01,  3.32611740e-01]],
    
            [[ 4.69421506e-01, -1.32875502e-01, -2.73067236e-01, ...,
               1.23477168e-01, -1.70634672e-01, -2.19240919e-01],
             [-2.19947383e-01, -2.69443840e-01, -9.54216644e-02, ...,
               3.69693309e-01, -2.55120367e-01, -1.17975459e-01],
             [-2.68796265e-01,  6.20718747e-02, -3.35199945e-02, ...,
               5.30212045e-01, -2.10855812e-01, -7.04443008e-02],
             ...,
             [ 3.28122489e-02, -1.71707019e-01, -1.68116689e-01, ...,
              -2.75321811e-01, -2.78297395e-01, -1.75988510e-01],
             [-1.73213229e-01, -1.46951750e-01, -2.46880293e-01, ...,
              -1.71832442e-01, -2.21999407e-01, -2.59935945e-01],
             [ 2.97643002e-02, -1.80615738e-01,  1.51156634e-02, ...,
              -1.73025712e-01, -1.61005661e-01, -2.09825993e-01]]],
    
    
           [[[-1.58392042e-01, -1.54539987e-01,  1.34316638e-01, ...,
              -9.55021158e-02, -8.48945230e-02, -2.70834297e-01],
             [-6.97174110e-04, -7.29148239e-02,  1.41448915e+00, ...,
              -2.24846750e-01, -1.54466080e-02, -2.76193082e-01],
             [-1.33245383e-04, -1.13120869e-01,  2.27327394e+00, ...,
              -2.64518142e-01, -2.55381137e-01, -2.73015022e-01],
             ...,
             [-1.44455671e-01, -8.57690722e-02, -2.77612418e-01, ...,
              -3.02869007e-02, -9.86584276e-02, -1.46415204e-01],
             [ 1.16128933e+00, -2.72845775e-01, -2.43864223e-01, ...,
              -1.99805394e-01, -2.48413160e-01, -2.70845562e-01],
             [ 1.28577992e-01, -2.78011262e-01, -2.44963020e-01, ...,
              -2.67480254e-01, -2.72504330e-01, -2.66309947e-01]],
    
            [[-2.70065844e-01, -1.79107904e-01, -1.81646079e-01, ...,
              -1.94967896e-01, -1.53732181e-01, -2.67610103e-01],
             [-3.81055987e-04, -1.74002394e-01,  1.89926922e+00, ...,
              -4.39652242e-02, -4.90484908e-02, -9.07121971e-02],
             [-1.20128661e-05, -2.54454464e-01,  8.48426223e-01, ...,
              -2.20052600e-01,  1.15242052e+00, -5.70149608e-02],
             ...,
             [ 2.11594757e-02, -2.77972817e-01, -2.26843506e-01, ...,
              -1.11994706e-01, -2.58470505e-01, -2.74723470e-01],
             [-8.28692224e-03, -2.74883151e-01, -2.28045538e-01, ...,
              -2.23705992e-01, -2.76689082e-01, -2.50134557e-01],
             [-1.44989967e-01, -1.98629096e-01, -1.78737238e-01, ...,
              -2.51328886e-01, -2.63755262e-01, -1.14081912e-01]],
    
            [[-2.70417869e-01, -1.75354928e-01, -2.76014984e-01, ...,
              -1.47353157e-01, -2.70418018e-01, -2.28406444e-01],
             [-2.08135173e-02, -1.36154607e-01,  1.00471234e+00, ...,
               5.60035467e-01,  8.24775934e-01,  8.36389601e-01],
             [-2.19639274e-04, -1.15469292e-01,  1.27220917e+00, ...,
              -2.49208450e-01,  4.59456491e+00,  1.53858864e+00],
             ...,
             [-9.13859308e-02, -1.71837077e-01, -8.45936537e-02, ...,
              -1.93602711e-01, -2.30517432e-01, -2.42947325e-01],
             [-2.22220764e-01, -1.96021095e-01, -1.88969627e-01, ...,
              -2.75553107e-01, -2.32264608e-01, -2.73459911e-01],
             [-2.31637239e-01, -2.71028996e-01, -1.50783047e-01, ...,
              -2.00889647e-01, -2.74831802e-01, -2.11859837e-01]],
    
            ...,
    
            [[-1.30756944e-01, -2.30774432e-01,  5.16755059e-02, ...,
              -1.48265660e-02, -2.77012616e-01, -2.34133855e-01],
             [-1.25778869e-01, -1.66347489e-01,  6.34154320e-01, ...,
              -3.88675071e-02, -4.37512584e-02,  3.29522282e-01],
             [-9.20335762e-03, -1.28363058e-01,  1.32050455e+00, ...,
              -1.51189387e-01, -3.96787375e-02, -4.94148806e-02],
             ...,
             [-2.76377022e-01, -2.21930042e-01, -2.29191199e-01, ...,
              -8.41262415e-02, -2.48659581e-01, -2.73202449e-01],
             [-2.95821577e-02, -1.35743767e-01, -2.54921079e-01, ...,
              -1.69194356e-01, -2.51802504e-01, -2.71716356e-01],
             [ 3.92804950e-01, -1.86559722e-01, -2.61084884e-01, ...,
              -2.23584011e-01, -2.52028793e-01, -2.71923959e-01]],
    
            [[ 8.16814661e-01, -1.81988865e-01,  4.28886831e-01, ...,
              -3.23468298e-02, -1.80819944e-01, -2.63299942e-01],
             [-1.80798426e-01, -1.10801503e-01, -2.56151021e-01, ...,
              -9.55144409e-03, -4.41952050e-02, -2.66233295e-01],
             [-1.21949799e-02, -1.64628386e-01, -2.38336623e-01, ...,
              -9.08483863e-02, -6.17808364e-02, -2.46774971e-01],
             ...,
             [-2.75008291e-01, -8.21388215e-02,  2.77412486e+00, ...,
              -1.11464038e-02, -2.76384860e-01, -2.40899757e-01],
             [-1.35664836e-01, -6.03039712e-02,  1.56128883e+00, ...,
              -1.80637836e-02, -2.28545949e-01, -2.78443307e-01],
             [ 3.25202763e-01, -1.86327845e-01, -1.66032493e-01, ...,
              -1.84678733e-01, -2.53040075e-01, -2.28614971e-01]],
    
            [[ 5.98812640e-01, -1.72792390e-01,  9.61212516e-01, ...,
              -6.73477128e-02, -2.78267294e-01, -2.77581692e-01],
             [-2.46516824e-01, -6.63086399e-02, -2.70487636e-01, ...,
              -1.38269868e-02, -8.51258337e-02, -1.50695831e-01],
             [-8.33060741e-02, -1.18941315e-01, -2.20533356e-01, ...,
              -6.76513240e-02, -4.26823273e-02, -1.67566940e-01],
             ...,
             [-2.26984352e-01, -5.70124611e-02,  4.97928476e+00, ...,
              -1.02482336e-02, -1.57701284e-01, -2.69395351e-01],
             [-2.75603920e-01, -2.65747271e-02,  3.80295897e+00, ...,
              -2.85676327e-02, -2.73546457e-01, -2.70781964e-01],
             [-8.25018510e-02, -1.30132228e-01,  6.44760311e-01, ...,
              -1.82860136e-01, -2.77700424e-01, -2.67708331e-01]]],
    
    
           ...,
    
    
           [[[-8.72370750e-02, -8.02151635e-02, -2.07252324e-01, ...,
              -2.78342783e-01, -6.65318891e-02, -1.30622506e-01],
             [-1.38879847e-02, -5.62571809e-02,  5.48470207e-02, ...,
              -1.36725828e-01, -9.83788539e-03,  3.39568824e-01],
             [-4.59985919e-02, -1.09949470e-01,  9.32768881e-02, ...,
              -1.42559156e-01, -2.32975297e-02,  1.77991226e-01],
             ...,
             [-2.50960350e-01, -1.89274028e-01, -1.56918094e-01, ...,
              -2.70820737e-01, -1.32820472e-01, -2.75506705e-01],
             [ 9.54854608e-01, -2.77933717e-01, -1.68318957e-01, ...,
              -2.61828274e-01, -2.55366892e-01, -2.77301610e-01],
             [ 1.10673213e+00, -2.01353282e-01, -1.65107042e-01, ...,
              -2.78222114e-01, -2.75286049e-01, -2.17536166e-01]],
    
            [[-1.17990412e-01, -2.17827976e-01, -1.29909068e-01, ...,
              -2.77196735e-01, -3.42917368e-02, -2.69651681e-01],
             [-6.76534697e-03,  4.73869413e-01,  1.81707251e+00, ...,
              -2.62882471e-01, -1.43890080e-04, -1.88328996e-01],
             [-7.21421279e-03,  2.73248017e-01,  1.74943221e+00, ...,
               5.98347843e-01, -1.21878972e-03, -1.56765297e-01],
             ...,
             [-1.92326427e-01, -2.78445303e-01, -1.25674590e-01, ...,
              -4.92908352e-04, -1.82203814e-01,  8.29596817e-01],
             [ 1.39962465e-01, -2.60071695e-01, -9.88833979e-02, ...,
              -2.76774526e-01, -2.76807010e-01,  3.79597872e-01],
             [ 1.12002850e+00, -2.28095680e-01, -1.40991360e-01, ...,
              -2.77925223e-01, -2.73149103e-01, -2.64005274e-01]],
    
            [[-3.22366990e-02, -1.87329724e-01,  1.09494992e-01, ...,
              -2.03022182e-01, -5.37840836e-02, -1.65133387e-01],
             [-9.39610451e-02,  3.67921090e+00, -2.66194373e-01, ...,
              -2.18328804e-01, -4.39024111e-03, -1.40929878e-01],
             [-1.44615844e-02,  2.92600060e+00,  1.66976601e-01, ...,
               2.55560803e+00, -7.67863728e-03, -2.15302691e-01],
             ...,
             [-2.60037165e-02, -5.41068576e-02,  2.17799783e-01, ...,
               1.89459968e+00, -2.30997968e-02,  2.75227070e-01],
             [-2.68949270e-01, -2.43444204e-01, -2.78046548e-01, ...,
               1.72430649e-02, -1.81473464e-01, -1.31210536e-01],
             [ 9.59257960e-01, -2.26180270e-01, -2.76416421e-01, ...,
              -2.72576749e-01, -2.78042912e-01, -2.40182832e-01]],
    
            ...,
    
            [[-2.78454721e-01, -6.98515251e-02,  3.09815347e-01, ...,
              -2.97882017e-02, -9.76684839e-02, -1.62977338e-01],
             [-8.86637121e-02, -2.31590003e-01, -2.72476166e-01, ...,
              -5.31610288e-03, -2.13039070e-01, -2.76526868e-01],
             [-1.51623739e-03,  3.84398162e-01, -2.77597219e-01, ...,
              -2.57153362e-01, -2.47258797e-01,  1.29506171e-01],
             ...,
             [-1.76102549e-04,  2.58553338e+00, -1.36806309e-01, ...,
               1.07199013e+00, -1.54101580e-01, -1.61872700e-01],
             [-2.49097906e-02, -2.76335418e-01, -2.52210855e-01, ...,
              -2.06571564e-01, -1.86338395e-01, -2.04979911e-01],
             [-1.83264419e-01, -4.12850305e-02,  1.50038564e+00, ...,
              -1.06588453e-02, -1.84389740e-01, -1.54660299e-01]],
    
            [[-2.56651133e-01, -1.95411146e-01, -1.91168711e-01, ...,
              -4.57138717e-02, -1.85490787e-01, -2.65899658e-01],
             [-2.75798470e-01,  1.09677243e+00, -3.36564817e-02, ...,
              -2.28952686e-03, -2.75454581e-01,  3.39205377e-02],
             [-1.64341077e-01,  7.03107476e-01, -8.97956043e-02, ...,
              -1.07268197e-02, -2.78459519e-01,  5.88954568e-01],
             ...,
             [-1.16658146e-02,  2.11844540e+00, -4.27959226e-02, ...,
              -9.54665840e-02, -8.34751949e-02, -1.95829347e-01],
             [-2.69105881e-01, -1.38524726e-01, -1.59095898e-01, ...,
              -3.58647592e-02, -1.50447413e-01, -2.21588820e-01],
             [-5.95483556e-02, -2.41733745e-01, -2.27175012e-01, ...,
              -3.06807808e-03, -1.57532796e-01, -3.60876769e-02]],
    
            [[-1.12574100e-01, -1.70575276e-01, -1.12084329e-01, ...,
              -8.70613679e-02, -2.01736122e-01, -2.61597514e-01],
             [ 8.06436390e-02,  6.34869993e-01, -3.41773368e-02, ...,
              -5.70262708e-02, -2.75076777e-01, -2.78387636e-01],
             [ 1.64181304e+00, -6.64364919e-02, -7.04070479e-02, ...,
              -2.96142306e-02, -1.96153328e-01,  6.54049754e-01],
             ...,
             [-2.33423784e-01, -6.12009950e-02, -8.76315162e-02, ...,
              -1.20845251e-02, -2.18260095e-01,  6.80188537e-01],
             [ 1.38561141e+00,  2.99036652e-01, -8.28647539e-02, ...,
              -9.90245417e-02, -2.76937366e-01, -2.74032772e-01],
             [ 2.81713247e-01,  2.19386673e+00, -7.10927024e-02, ...,
              -4.50428948e-02, -1.35658726e-01, -1.11438878e-01]]],
    
    
           [[[ 3.43743861e-02, -9.85911116e-02, -2.76629686e-01, ...,
              -1.61686016e-03, -2.77957350e-01, -1.52399182e-01],
             [-2.19443232e-01, -2.64384985e-01, -1.86834425e-01, ...,
              -2.78324038e-01, -2.68305182e-01,  1.07347921e-01],
             [-2.25075576e-02, -2.33647630e-01, -1.51285067e-01, ...,
              -2.00015679e-01, -1.05487250e-01, -2.01421991e-01],
             ...,
             [-2.18374103e-01, -8.22047219e-02, -2.57310003e-01, ...,
               1.26660928e-01, -2.77071238e-01, -2.78286695e-01],
             [-1.44585073e-01,  3.07473272e-01, -2.00219929e-01, ...,
               3.81996095e-01, -2.07302317e-01, -2.75636226e-01],
             [-2.37355232e-01,  2.66891867e-01, -2.76826024e-01, ...,
              -1.21594548e-01, -2.56618947e-01, -2.78431058e-01]],
    
            [[-4.88844998e-02,  4.17249441e-01, -2.75775701e-01, ...,
               3.59107405e-01, -2.67986685e-01,  5.87721802e-02],
             [-1.52231008e-02,  8.72759461e-01, -1.07125685e-01, ...,
               1.73579484e-01, -8.86649862e-02, -2.16370940e-01],
             [-1.73246117e-05,  4.95919675e-01, -2.51940757e-01, ...,
               8.22381437e-01, -9.79360100e-03, -2.09503230e-02],
             ...,
             [-3.75733450e-02,  2.96666175e-01, -1.79147154e-01, ...,
               4.76589426e-02, -2.39267662e-01, -2.76888520e-01],
             [-4.48574051e-02,  4.89039809e-01, -1.45519286e-01, ...,
               1.26574293e-01, -2.78428644e-01, -2.72274792e-01],
             [-2.67087668e-01,  7.32674837e-01, -2.77157038e-01, ...,
               1.10863872e-01, -2.49177337e-01, -2.78456062e-01]],
    
            [[-1.25527531e-01,  3.68375391e-01, -2.77946532e-01, ...,
              -1.40466675e-01, -2.71631271e-01, -1.16052711e-02],
             [-4.33425233e-02,  1.48671675e+00, -1.14765428e-01, ...,
              -2.78145671e-01, -1.93700925e-01, -7.32561052e-02],
             [-2.94961588e-04,  2.00645328e+00, -2.75350481e-01, ...,
               3.03754985e-01, -2.49249548e-01, -8.91295224e-02],
             ...,
             [-1.48574740e-01, -1.14746705e-01, -2.66699225e-01, ...,
              -2.68481433e-01, -2.54665107e-01, -1.89164490e-01],
             [-6.35334551e-02,  1.20898879e+00, -2.17275113e-01, ...,
              -1.94430828e-01, -2.45765209e-01, -2.15095937e-01],
             [-2.41778046e-01,  1.15034413e+00, -2.57307023e-01, ...,
               1.05270267e-01, -2.77873605e-01, -2.76997596e-01]],
    
            ...,
    
            [[-5.91951385e-02, -1.09557051e-03, -2.76242763e-01, ...,
              -1.58721045e-01, -2.30653435e-01,  3.31761867e-01],
             [-6.58862889e-02,  1.10292447e+00, -1.69566974e-01, ...,
              -1.41701654e-01, -1.21614173e-01, -2.73776382e-01],
             [-1.42184552e-03,  5.17828405e-01, -1.04390562e-01, ...,
              -2.45921344e-01, -2.74453491e-01, -2.30706677e-01],
             ...,
             [-8.29642192e-02, -9.10161659e-02,  1.10575593e+00, ...,
               6.78003967e-01, -2.68202424e-01, -1.64828077e-01],
             [-1.79391846e-01, -2.70889938e-01,  3.09251159e-01, ...,
               1.90220952e-01,  6.35661602e-01,  2.39486367e-01],
             [ 5.42139947e-01, -1.41797394e-01,  8.89474869e-01, ...,
               6.78163946e-01, -5.88194095e-02,  8.71191084e-01]],
    
            [[ 1.81718960e-01, -1.59788921e-01, -1.54122725e-01, ...,
               1.31310269e-01, -3.28498147e-02,  4.45225269e-01],
             [-1.74551576e-01,  7.04720393e-02,  2.71545321e-01, ...,
              -2.78428674e-01, -1.79309875e-01,  1.96220741e-01],
             [-4.23351489e-02,  2.13889456e+00,  2.60343105e-02, ...,
              -1.30943537e-01, -1.60977855e-01, -1.39593288e-01],
             ...,
             [-3.27864215e-02, -2.73560792e-01, -1.10333309e-01, ...,
              -2.66689211e-01, -1.04721159e-01, -7.50680342e-02],
             [ 3.54832697e+00, -2.14747831e-01, -8.59586149e-02, ...,
               1.85989046e+00,  1.82919824e+00,  2.32544708e+00],
             [ 2.32870603e+00, -2.68822223e-01,  3.61790031e-01, ...,
               3.61738896e+00,  1.94284117e+00,  1.91209769e+00]],
    
            [[ 9.12495136e-01, -2.43250027e-01, -1.41058922e-01, ...,
               2.29835555e-01,  1.91147715e-01,  2.35202253e-01],
             [ 6.73226237e-01, -2.75807261e-01,  9.98345852e-01, ...,
               2.98932046e-01, -3.22253294e-02,  3.75563711e-01],
             [ 1.33077419e+00,  5.47375381e-01,  1.22946107e+00, ...,
               8.05068463e-02,  7.95594826e-02,  1.49355960e+00],
             ...,
             [ 4.87114334e+00, -2.52808541e-01, -2.30022833e-01, ...,
               3.27479887e+00,  3.43264151e+00,  4.58884668e+00],
             [ 4.44593811e+00, -2.74057448e-01, -2.45652884e-01, ...,
               6.39951611e+00,  4.85059118e+00,  5.62162161e+00],
             [ 2.95805025e+00, -2.08218187e-01, -2.64955968e-01, ...,
               5.38180542e+00,  3.34471488e+00,  3.17258072e+00]]],
    
    
           [[[ 4.23961133e-03, -2.54410207e-01,  1.77205831e-01, ...,
              -2.76179343e-01, -2.45827317e-01, -2.00336933e-01],
             [ 1.98000342e-01, -2.30686083e-01, -1.61635235e-01, ...,
              -2.11586192e-01, -1.34889752e-01, -1.12757601e-01],
             [ 1.00867577e-01, -2.65095651e-01, -2.55755991e-01, ...,
              -2.62598574e-01, -1.64183125e-01,  3.09886366e-01],
             ...,
             [-2.55796015e-01, -2.60150194e-01, -2.69342601e-01, ...,
              -2.47805879e-01,  5.12923524e-02,  9.03338939e-02],
             [ 3.42678875e-01, -2.75507390e-01, -1.83733795e-02, ...,
              -2.33488917e-01, -1.43242434e-01, -2.76055485e-01],
             [ 7.65427768e-01, -2.41234839e-01,  1.53833032e-01, ...,
              -2.77812302e-01,  7.00380802e-02, -2.73211449e-01]],
    
            [[ 1.15400717e-01, -2.76223153e-01,  1.15090869e-01, ...,
              -2.68905342e-01, -1.25681370e-01,  1.76727220e-01],
             [-1.71382770e-01, -2.76378542e-01, -3.93715575e-02, ...,
              -1.07180245e-01, -5.77749647e-02,  7.28266239e-01],
             [-1.30059108e-01, -2.58924842e-01, -2.68486321e-01, ...,
              -2.76245892e-01, -2.51626879e-01,  1.65519571e+00],
             ...,
             [-1.97694963e-03, -4.75785099e-02,  1.56057250e+00, ...,
              -2.44231939e-01, -1.58680052e-01, -1.82329401e-01],
             [-9.29584429e-02, -9.61565897e-02,  6.94176495e-01, ...,
              -2.77557045e-01, -1.04646869e-01, -8.98678005e-02],
             [-3.42279449e-02, -2.53337294e-01,  1.91377625e-01, ...,
              -2.22715482e-01, -2.74775237e-01, -2.60692358e-01]],
    
            [[-2.68976361e-01, -2.71063924e-01, -6.04811087e-02, ...,
              -2.56788969e-01, -2.72232890e-01,  6.86254427e-02],
             [-1.35171905e-01, -1.83185592e-01,  8.55969429e-01, ...,
               8.64224851e-01, -1.80061147e-01,  2.52423912e-01],
             [-7.55626187e-02, -1.05332211e-01,  7.76401341e-01, ...,
               4.14731652e-01, -7.37403333e-02,  2.18503818e-01],
             ...,
             [-4.28551211e-05, -1.77738315e-03,  3.25128698e+00, ...,
               6.38110352e+00, -2.67208368e-01, -2.92591900e-02],
             [-4.33086697e-03, -2.90950574e-02,  1.22706878e+00, ...,
               5.14526749e+00, -2.39911482e-01, -9.07121077e-02],
             [ 9.73667130e-02, -2.17390984e-01,  1.82722639e-02, ...,
               1.19670856e+00, -4.36254442e-02, -2.62272030e-01]],
    
            ...,
    
            [[-1.32719846e-02, -2.74769396e-01, -2.76966482e-01, ...,
              -2.28783056e-01, -2.45990366e-01, -2.75765777e-01],
             [-2.55895287e-01, -2.11254060e-01, -2.75735348e-01, ...,
               2.04505277e+00, -2.38144010e-01, -2.46145919e-01],
             [-7.34059811e-02, -2.45937303e-01, -2.74773806e-01, ...,
               2.63464713e+00, -2.70294368e-01, -2.07215264e-01],
             ...,
             [-1.82927120e-02, -2.11400598e-01, -2.64541000e-01, ...,
              -1.22690730e-01,  4.04633552e-01,  3.54419440e-01],
             [-2.75454640e-01, -2.06104010e-01,  1.08944547e+00, ...,
              -2.78464198e-01, -2.24533990e-01, -2.55395830e-01],
             [ 9.73686516e-01, -2.09215716e-01,  7.00637877e-01, ...,
              -2.04857245e-01, -1.09723285e-01, -2.68376976e-01]],
    
            [[ 2.09625816e+00, -2.40168571e-01,  2.77417362e-01, ...,
              -5.59915751e-02, -2.51614958e-01, -2.04363644e-01],
             [-2.73659557e-01, -1.34360954e-01, -2.77307749e-01, ...,
               7.75246084e-01, -2.63685763e-01, -2.66373426e-01],
             [-1.48186713e-01, -2.26919219e-01, -2.70572990e-01, ...,
               2.35907030e+00, -7.83741996e-02, -2.40872398e-01],
             ...,
             [ 3.15418392e-01, -2.78180897e-01,  1.47089884e-01, ...,
              -2.76470840e-01,  1.12108909e-01, -1.92335472e-01],
             [ 1.35463309e+00, -9.43021327e-02,  2.49927258e+00, ...,
              -2.66686887e-01,  9.91466284e-01, -2.62450486e-01],
             [ 2.69641399e+00, -1.98664013e-02,  2.87792039e+00, ...,
              -1.76335201e-01, -2.75520504e-01, -1.54551998e-01]],
    
            [[ 2.25460219e+00, -2.29545057e-01,  7.19489276e-01, ...,
              -1.46996761e-02, -2.56974429e-01,  2.10201070e-01],
             [ 9.66896489e-02, -2.15796664e-01, -2.50947535e-01, ...,
              -2.59889185e-01, -2.60895252e-01,  1.05790734e-01],
             [-2.78464437e-01, -2.75186807e-01, -2.66715109e-01, ...,
              -2.64783144e-01, -1.05178565e-01,  4.61720973e-01],
             ...,
             [ 1.15485799e+00, -1.55356184e-01, -1.62961870e-01, ...,
              -7.94149265e-02, -2.78311014e-01,  7.28313923e-01],
             [ 2.17598176e+00, -8.69607255e-02,  2.29728460e-01, ...,
              -1.48992896e-01,  2.41546303e-01,  4.84176666e-01],
             [ 1.63772357e+00, -4.06442173e-02,  1.13258696e+00, ...,
              -2.36238405e-01, -2.71336257e-01,  6.56960234e-02]]]],
          dtype=float32)>, <tf.Tensor: shape=(32, 2), dtype=float32, numpy=
    array([[0., 1.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [0., 1.],
           [0., 1.],
           [0., 1.],
           [0., 1.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [1., 0.]], dtype=float32)>)
    




    array([[0., 1.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [0., 1.],
           [0., 1.],
           [0., 1.],
           [0., 1.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [0., 1.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [0., 1.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [1., 0.],
           [1., 0.]], dtype=float32)



* take(1)만 해도, Batch Size만큼 읽는다는 것을 알 수 있습니다.


* 내용을 보니 제대로 읽어오는 것 같습니다.

   

   

   

   

   

   

   

## 3. Model Define   


* Data도 준비되었으니, EfficientNet에서 추출한 Feature를 분류할 Simple Dense Net을 하나 정의하겠습니다.


* Input Shape 신경 써주고, 적당하게 만들어 줍니다.


```python
model = tf.keras.Sequential()

model.add( tf.keras.layers.InputLayer(input_shape=(7,7,1280)) )
model.add( tf.keras.layers.GlobalAveragePooling2D() )

model.add( tf.keras.layers.BatchNormalization() )
model.add( tf.keras.layers.Dropout(0.25) )
model.add( tf.keras.layers.Dense(256 , activation='relu') )

model.add( tf.keras.layers.BatchNormalization() )
model.add( tf.keras.layers.Dropout(0.25) )
model.add( tf.keras.layers.Dense(64 , activation='relu') )

model.add( tf.keras.layers.BatchNormalization() )
model.add( tf.keras.layers.Dropout(0.25) )
model.add( tf.keras.layers.Dense(2 , activation='softmax') )
```


```python
model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    global_average_pooling2d (Gl (None, 1280)              0         
    _________________________________________________________________
    batch_normalization (BatchNo (None, 1280)              5120      
    _________________________________________________________________
    dropout (Dropout)            (None, 1280)              0         
    _________________________________________________________________
    dense (Dense)                (None, 256)               327936    
    _________________________________________________________________
    batch_normalization_1 (Batch (None, 256)               1024      
    _________________________________________________________________
    dropout_1 (Dropout)          (None, 256)               0         
    _________________________________________________________________
    dense_1 (Dense)              (None, 64)                16448     
    _________________________________________________________________
    batch_normalization_2 (Batch (None, 64)                256       
    _________________________________________________________________
    dropout_2 (Dropout)          (None, 64)                0         
    _________________________________________________________________
    dense_2 (Dense)              (None, 2)                 130       
    =================================================================
    Total params: 350,914
    Trainable params: 347,714
    Non-trainable params: 3,200
    _________________________________________________________________
    

   

   

   

* Optimizer 선택해서 설정하고, Compile한 후에 Train시작하겠습니다.   


```python
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)
```


```python
model.compile(optimizer=optimizer, 
              loss="categorical_crossentropy", metrics=["accuracy"]
             )
```


```python
EPOCHS = 5

hist = model.fit(Train_Dataset, 
                 epochs=EPOCHS, 
                 validation_data=Val_Dataset, 
                 verbose=1)
```

    Epoch 1/5
    621/621 [==============================] - 285s 458ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 0.0319 - val_accuracy: 0.9887
    Epoch 2/5
    621/621 [==============================] - 362s 582ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.0371 - val_accuracy: 0.9881
    Epoch 3/5
    621/621 [==============================] - 384s 618ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 0.0327 - val_accuracy: 0.9895
    Epoch 4/5
    621/621 [==============================] - 473s 761ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 0.0291 - val_accuracy: 0.9899
    Epoch 5/5
    621/621 [==============================] - 436s 702ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0357 - val_accuracy: 0.9895
    

   

   

* 첫번째 Epoch에서 Train / Val. Set 모두에서 이미 높은 Accuracy를 보이네요.


* 제대로 동작하는 것 같네요.

   

   


```python
import matplotlib.pyplot as plt
```


```python
plt.plot(hist.history["accuracy"])
plt.plot(hist.history["val_accuracy"])
plt.title("model accuracy")
plt.ylabel("accuracy")
plt.xlabel("epoch")
plt.legend(["train", "validation"], loc="upper left")
plt.show()
```


![png](output_112_0.png)


   

   

   

   

## 4. Summary


* 이번 Post에서는 TFReocrd File Format을 읽어서 실제 Train에 적용시키는 방법까지 알아보았습니다.


* 중요한 것은 TFReocrd File을 사용하기 위해서는 해당 Dataset을 만들때 사용한 구조( Feature )를 반드시 알고 있어야 한다는 것입니다.
