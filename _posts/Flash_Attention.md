---
title: "Flash Attention"
date: 2025-03-26 08:26:28 -0400
categories: Deep Learning
---

<br>
<br>

Flash Attention은 Stanford 연구진에 의해 제안되었으며, 기존 Transformer 모델의 핵심 구성 요소인 Attention 메커니즘을 개선한 기술입니다.

<br>

