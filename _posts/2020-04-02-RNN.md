---
title: "RNN(Recurrent Neural Network)"
date: 2020-04-02 08:26:28 -0400
categories: DeepLearning RNN
---

# RNN( Recurrent Neural Network )
<br>
<br>
<br>
<br>
<br>   

* 이번 Post에서는 RNN(Recurrent Neural Network)에 대해서 다루어 보도록 하겠습니다.
* 주된 내용은 Standford 강의자료([CS231n 강좌](http://cs231n.stanford.edu/syllabus.html) )를 참고하였습니다.
* Sequence Data는 다음과 같은 특징을 가집니다.
     - 음악 , 영상 , 문장 , 날씨 , 주가 등은 각각의 Data가 개별적이 아닌, 연속적인 Data(Sequence Data)라는 점입니다.
     - 앞쪽의 Data가 뒤쪽의 Data에 영향을 준다는 의미입니다.  
     
     
* RNN 이외의 다른 ML / DL 기법이 이런 Sequence Data를 다루려면, Sequence가 가지는 전체적인 흐름을 하나의 Data 형태로 표현해야만 합니다.  

* 그래서, ML(Machine Learning) / NN(Neural Net) / CNN(Convolution Neural Net)은 이런 속성의 Data를 다루기 어렵습니다.
* Sequence Data를 처리할 때는 이전의 결과가 현재의 결과에 영향을 미칠 수 있어야 하며, 이런 Sequence 형태의 Data를 다룰 수 있는 Neural Net의 형태가 RNN입니다.

<br>
<br>
<br>
<br>
<br>


### 0. RNN의 기본 구조   

   

#### 다음은 RNN Cell의 기본 구조를 나타냅니다.   

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_00.png">
</p>
   

* 위의 형태가 RNN의 기본적인 Cell을 나타냅니다.
* 입력(X<sub>t</sub>)을 받아서 어떤 연산을 거친 후 출력(h<sub>t</sub>)를 내보내는 구조는 일반 Perceptron의 동작과 동일합니다.
* 다른점이 있다면, 출력이 하나 더 있고, 그 출력이 다시 입력으로 들어온다는 점입니다.
* 이를 이해하기 쉽게 옆으로 펼쳐보겠습니다.


<span style="color:red">내용</span>
