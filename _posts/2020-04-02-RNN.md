---
title: "RNN(Recurrent Neural Network)"
date: 2020-04-02 08:26:28 -0400
categories: DeepLearning RNN
---

# RNN( Recurrent Neural Network )
<br>
<br>
<br>
<br>
<br>   

* 이번 Post에서는 RNN(Recurrent Neural Network)에 대해서 다루어 보도록 하겠습니다.
* 주된 내용은 Standford 강의자료([CS231n 강좌](http://cs231n.stanford.edu/syllabus.html) )를 참고하였습니다.
* Sequence Data는 다음과 같은 특징을 가집니다.
     - 음악 , 영상 , 문장 , 날씨 , 주가 등은 각각의 Data가 개별적이 아닌, 연속적인 Data(Sequence Data)라는 점입니다.
     - 앞쪽의 Data가 뒤쪽의 Data에 영향을 준다는 의미입니다.  
     
     
* RNN 이외의 다른 ML / DL 기법이 이런 Sequence Data를 다루려면, Sequence가 가지는 전체적인 흐름을 하나의 Data 형태로 표현해야만 합니다.  

* 그래서, ML(Machine Learning) / NN(Neural Net) / CNN(Convolution Neural Net)은 이런 속성의 Data를 다루기 어렵습니다.
* Sequence Data를 처리할 때는 이전의 결과가 현재의 결과에 영향을 미칠 수 있어야 하며, 이런 Sequence 형태의 Data를 다룰 수 있는 Neural Net의 형태가 RNN입니다.

<br>
<br>
<br>
<br>
<br>


### 0. RNN의 기본 구조   

   

#### 다음은 RNN Cell의 기본 구조를 나타냅니다.   
<br>
<br>
<br>

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_00.png">
</p>

<br>
<br>
<br>   

* 위의 형태가 RNN의 기본적인 Cell을 나타냅니다.
* 입력(X<sub>t</sub>)을 받아서 어떤 연산을 거친 후 출력(h<sub>t</sub>)를 내보내는 구조는 일반 Perceptron의 동작과 동일합니다.
* <span style="color:red">다른점이 있다면, 출력이 하나 더 있고, 그 출력이 다시 입력으로 들어온다는 점입니다.</span>
* 이를 이해하기 쉽게 옆으로 펼쳐보겠습니다.

<br>
<br>
<br>

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_01.png">
</p>

<br>
<br>
<br>

* 위의 오른쪽 그림과 같이 Cell을 펼쳐보면, Cell의 출력이 다음 Cell의 입력으로 들어가는 모습을 볼 수 있습니다.
* 즉, **이전의 결과가 현재의 출력에 영향을 미친다는 것**을 뜻하며, 이것이 Recurrent의 의미이기도 합니다.

<br>
<br>
<br>   

   

* 이를 수식으로 살펴보면 아래와 같습니다.

<br>
<br>
<br>   

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_02.png">
</p>
   
<br>
<br>
<br>   
   

* 이를 수식으로 살펴보면, 위와 같이 New State는 이전 State와 현재의 입력의 함수로 표현됩니다.
* RNN에서 Function(F<sub>w</sub>)는 모든 RNN에 대해서 동일하며, 주로 tanh을 사용합니다.

   
<br>
<br>
<br>   
   
<br>
<br>
<br>   
   

   

### 1. Calculating Values

#### RNN에서 각각의 값들이 구해지는 과정을 수식으로 살펴보도록 하겠습니다.

   

   

   

* 우선 다음 Cell의 출력으로 나갈 h<sub>t</sub>값은 아래와 같이 계산합니다.   
<br>
<br>
<br>

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_03.png">
</p>
<br>
<br>
<br>

다음 State로 넘길 값은 현재의 입력(x<sub>t</sub>)와 이전 Cell에서 전달된 값(h<sub>t-1</sub>)으로 정해집니다.

   

위의 수식을 풀어쓰면 아래와 같이 쓸 수 있습니다.

<br>
<br>
<br>


<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_04.png">
</p>
<br>
<br>
<br>


W<sub>hh</sub>와 W<sub>xh</sub>는 각 출력을 뽑아낼 때 사용한 Weight입니다.

   
<br>
<br>
<br>

   

해당 Cell의 출력을 계산할 때는 아래와 같은 수식으로 계산됩니다.

   
<br>
<br>
<br>

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_05.png">
</p>
   
<br>
<br>
<br>

* 해당 Cell의 출력을 뽑아낼 때는 W<sub>hy</sub> Weight를 사용합니다.  
* 위 수식에서 알 수 있듯이 각각의 값에 적용되는 Weight가 모두 다릅니다.

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

### 2. Example - Character Level Simple Language Model

* 간단한 예제를 통해서 RNN이 어떤 식으로 동작하는지 살펴보도록 하겠습니다.
* 실제 동작하는 Code가 아니라, 개념만 도식적으로 살펴보겠습니다.

#### Example Training Sequence

## 'hello'

* 우리가 학습하고자 하는 단어는 'hello'입니다.
* 첫 입력 문자로 'h'를 입력하면 'ello'가 출력되도록 하는 Model을 학습하고자 한다고 가정해 봅시다.
  
  
* Train에 사용될 문자의 종류는 **h, e, l, o** 이렇게 4개 입니다.

   
<br>
<br>
<br>
   

* 아래와 같은 구조가 되겠죠 
<br>
<br>
<br>

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_06.png">
</p>
   

<br>
<br>
<br>
   

   

   

#### 전체적인 Train 과정은 다음 그림과 같을 것입니다.

   
<br>
<br>
<br>

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_07.png">
</p>

<br>
<br>
<br>


* 가장 아래쪽은 입력을 나타냅니다. 각 문자를 One-Hot Encoding해서 입력으로 넣어주고 있습니다.
* RNN 각 Cell에서 해당 문자에 Weight를 곱해서 출력과 함께 다음 Cell로 넘길 값도 계산해 주고 있습니다.
* 출력으로 나온 값은 실제 Target 값과 비교하며 Backpropargation으로 Weight를 조절해 나갑니다.
* 이와 같은 방식으로 Model을 학습시킵니다.

<br>
<br>
<br>   
<br>
<br>
<br>   
<br>
<br>
<br>
   

   

### 3. Application of RNN

* RNN을 이용한 분야는 매우 다양한데, 각각 어떤 분야에서 사용되는지 알아보도록 하겠습니다. 

<br>
<br>
<br>

#### 3.1. Language Model

   * Language Model은 단어 시퀀스에 확률을 할당(assign)하는 일을 하는 모델입니다. 
   * Language Model 은 가장 자연스러운 단어 시퀀스를 찾아내는 모델입니다. 
   * 즉, 단어 시퀀스에 확률을 할당하게 하기 위해서 가장 보편적으로 사용되는 방법은 언어 모델이 이전 단어들이 주어졌을 때 다음 단어를 예측
   하도록 하는 것입니다.  
   

   * 학습할 문장이 주어지면, RNN은 이를 학습하여, 주어진 단어 다음에 올 가능성이 가장 높은 단어 시퀀스의 확률을 예측하는 Model입니다.
<br>
<br>
<br>

**언어 모델 관련 참고 자료**
  - [https://www.cs.bgu.ac.il/~elhadad/nlp18/nlp02.html](https://www.cs.bgu.ac.il/~elhadad/nlp18/nlp02.html)
  - [http://www.marekrei.com/pub/Machine_Learning_for_Language_Modelling_-_lecture3.pdf](http://www.marekrei.com/pub/Machine_Learning_for_Language_Modelling_-_lecture3.pdf)

<br>
<br>
<br>

**언어 모델링 및 텍스트 생성에 관련된 연구 논문들**   

* [Recurrent neural network based language model](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)
* [Extensions of Recurrent neural network based language model](http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf)
* [Generating Text with Recurrent Neural Networks](https://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf)

<br>
<br>
<br>

#### 3.2. Machine Translation

* Machine Translation는 입력이 단어들의 Sequence라는 점에서 Language Modeling과 비슷하지만, 출력값이 다른 언어로 되어있는 단어들의 Sequence라는 점에서 차이가 있습니다. 
* 네트워크 상에서의 중요한 차이점은, 입력값을 전부 다 받아들인 다음에서야 네트워크가 출력값을 내보낸다는 점에 있는데, 번역 문제에서는 어순이 다른 문제 등이 있기 때문에 대상 언어의 문장의 첫 단어를 알기 위해선 번역할 문장 전체를 봐야 할 수도 있기 때문입니다.

   

<br>
<br>
<br>

<p align="center">
  <img src="/assets/RNN_Doc_Img/pic_08.png">
</p>
<br>
<br>
<br>   

**번역에 관련된 연구 논문들**

* [A Recursive Recurrent Neural Network for Statistical Machine Translation](https://www.aclweb.org/anthology/P14-1140.pdf)
* [Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)
* [Joint Language and Translation Modeling with Recurrent Neural Networks](https://www.aclweb.org/anthology/D13-1106.pdf)

<br>
<br>
<br>

#### 3.3. Speech Recognition   
* 사운드 웨이브의 음향 신호(acoustic signal)를 입력으로 받아들이고, 출력으로는 음소(phonetic segment)들의 시퀀스와 각각의 음소별 확률 분포를 추측할 수 있는 Model입니다.

   

**음성 인식에 관련된 연구 논문들**   

* [Towards End-to-End Speech Recognition with Recurrent Neural Networks](http://proceedings.mlr.press/v32/graves14.pdf)
* [LSTM RNN-based Korean Speech Recognition System Using CTC](https://www.researchgate.net/publication/318703474_LSTM_RNN-based_Korean_Speech_Recognition_System_Using_CTC)
* [Recognizing Speech Commands Using Recurrent Neural Networks with Attention](https://towardsdatascience.com/recognizing-speech-commands-using-recurrent-neural-networks-with-attention-c2b2ba17c837)


<br>
<br>
<br>

#### 3.4. Image Video Captioning  

* Convolutional Neural Network(CNN)과 RNN을 함께 사용한다면, 임의의 이미지를 텍스트로 설명해주는 시스템을 만드는 것도 가능합니다.
이에 대한 훌륭한 Post가 있어 공유드립니다.

* [Image Captioning에 관한 훌륭한 Post !!](https://moonlight314.github.io/project/imagecaption/ImageCaptioning/)

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


### 4. Long-Term Dependency

* **Training RNN is challenging !!**   

* RNN Model의 장점은 이전 정보들로부터 다음의 정보를 예측할 수 있다는 것입니다.

* 다만, 다음의 정보를 예측하는데 필요한 정보가 최근에 있었다면 RNN은 쉽게 이를 예측합니다.

* 'The clouds are in the sky’라는 문장에서 ‘The clouds are in the’를 보고 다음에 올 ‘sky’를 예측하는 것은 쉽습니다.

* 그러나, ‘I grew up in France… I speak fluent’를 보고 뒤에 나올 ‘French’를 예측하기란 앞의 ‘sky’를 예측하기보다는 어렵습니다.

* <span style="color:red">즉, 예측해야할 정보를 알아내기 위한 정보의 거리가 멀수록 RNN 학습은 어려워집니다.</span>

* Multi Layer가 되면 학습이 어려워집니다.( vanishing/exploding gradient). 
  - [On the difficulty of training recurrent neural networks](http://proceedings.mlr.press/v28/pascanu13.pdf)

* 이론적으로는 RNN으로 하여금 이런 Long-Term Dependency를 개선하도록 Parameter 조정을 하도록 할 수 있습니다만, 

* 실제로 RNN이 이런 문제를 개선할 수 없다는 것이 밝혀졌습니다. 
  - [http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf](http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf)
  - [http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf](http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf)


* <span style="color:red">**이런 RNN의 구조적인 문제점을 개선하기 위해서 나온 것이 LSTM 입니다.**</span>
