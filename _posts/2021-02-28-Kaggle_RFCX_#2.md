 ---
title: "Kaggle Competition - Rainforest Connection Species Audio Detection #2"
date: 2021-02-28 08:26:28 -0400
categories: Kaggle
---
### Kaggle Competition - Rainforest Connection Species Audio Detection - Revision #02

<br>
<br>
<br>
<br>

* ì´ë²ˆ Postì—ì„œëŠ” ì§€ë‚œ ë²ˆì— ì˜¬ë ¸ì—ˆë˜ Kaggle - Rainforest Connection Species Audio Detection Compepition 2ë²ˆì§¸ Postì…ë‹ˆë‹¤.

<br>
<br>
<br>

### 0. ë³€ê²½ ë‚´ìš©

* ì´ë²ˆì—ëŠ” ì§€ë‚œ Postì—ì„œ ë‹¤ë£¨ì—ˆë˜ ë°©ë²•ê³¼ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë„ì „í•´ ë³´ê³ ì í•©ë‹ˆë‹¤.


* ì§€ë‚œë²ˆì— ì‚¬ìš©í–ˆë˜ Featureì¸ MEL Spectogramê³¼ MFCC ì¤‘ì—ì„œ **MEL Spec.** ë§Œ ì‚¬ìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


* ì§€ë‚œ ë²ˆì—ëŠ” LightGBMì„ ì‚¬ìš©í–ˆì—ˆì§€ë§Œ, ì´ë²ˆì—ëŠ” MEL Spec.ì„ ì´ìš©í•´ì„œ **CNN**ì„ ì ìš©í•´ ë³´ê³ ì í•©ë‹ˆë‹¤.


* ì´ë²ˆ Competitionì—ì„œ ì œê³µë˜ëŠ” Datasetì€ 1216ê°œ ì´ê³ , ë¶„ë¥˜í•´ì•¼í•  ClassëŠ” ì´ 24ê°œì…ë‹ˆë‹¤.


* Datasetì´ Deep Learningì„ ëŒë¦¬ê¸°ì—” ë„ˆë¬´ë‚˜ ë¶€ì¡±í•œ ìˆ˜ì…ë‹ˆë‹¤.


* ì´ëŸ° ìƒí™©ì—ì„œëŠ” Overfittingì´ ë°œìƒí•  í™•ë¥ ì´ ë§¤ìš° ë†’ê¸° ë•Œë¬¸ì— Data Augmentationì„ ìˆ˜í–‰í•˜ê¸°ë¡œ í•˜ê² ìŠµë‹ˆë‹¤.


* CNNì„ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆê³ , ìƒˆë¡­ê²Œ CNN Layer êµ¬ì¡°ë¥¼ ë§Œë“¤ê¸° ë³´ë‹¤ëŠ” ê¸°ì¡´ì— ìˆëŠ” í›Œë¥­í•œ Modelì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ê¸°ë¡œ í•˜ê² ìŠµë‹ˆë‹¤.


* ì €ëŠ” ì´ë²ˆì— **ResNet50**ì„ ì‚¬ìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


* Data Augmentationê³¼ ResNetì„ ì‹¤ì‹œê°„ìœ¼ë¡œ Trainingì— ì‚¬ìš©í•˜ê¸°ì—” Memory ì œí•œë•Œë¬¸ì— ì´ì „ì— ë‹¤ë£¨ì—ˆë˜ **Custom Generator**ë¥¼ ì ìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

<br>
<br>
<br>
<br>
<br>
<br>

### 1. Augmentation for Sound Data 

* ImageDataGeneratorì—ëŠ” ë‹¤ì–‘í•œ Augmentation ê¸°ë²•ë“¤ì´ ë§ˆë ¨ë˜ì–´ ìˆì§€ë§Œ, ì‚¬ì‹¤ ì´ ê¸°ë²•ë“¤ì€ ëª¨ë‘ Imageë“¤ì— ëŒ€í•œ Augmentation ê¸°ë²•ë“¤ì…ë‹ˆë‹¤.


* ì§€ê¸ˆ ìš°ë¦¬ê°€ ë‹¤ë£¨ëŠ” Datasetì€ CNNì„ ì´ìš©í•˜ëŠ”ê²ƒì€ ë§ì§€ë§Œ, Imageê°€ ì•„ë‹Œ Sound Dataì…ë‹ˆë‹¤.


* ê·¸ë˜ì„œ, Imageì— ì ìš©í•  ìˆ˜ ìˆëŠ” Augmentation ê¸°ë²•ë“¤ì´ ì•„ë‹Œ Soundì— ì ìš©ê°€ëŠ¥í•œ Augmentation ê¸°ë²•ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤.


* Sound Data Augmentationì— ì ìš©ê°€ëŠ¥í•œ ë‹¤ì–‘í•œ ê¸°ë²•ë“¤ì´ ì†Œê°œëœ ì¢‹ì€ ê¸€ì´ ìˆì–´ ì†Œê°œë“œë¦½ë‹ˆë‹¤.

  [RFCX: Audio Data Augmentation(Japanese+English)](https://www.kaggle.com/hidehisaarai1213/rfcx-audio-data-augmentation-japanese-english)

* ì €ë„ ì´ë²ˆ Datasetì—ëŠ” ìœ„ì—ì„œ ì†Œê°œí•œ ë‹¤ì–‘í•œ ê¸°ë²•ë“¤ì„ ì ìš©í•  ì˜ˆì •ì…ë‹ˆë‹¤.   


<br>
<br>
<br>

* Sound Data Augmentationì„ ìœ„í•´ì„œ 'colorednoise'ë¼ëŠ” Packageë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

* ìì„¸í•œ ì†Œê°œì™€ ì‚¬ìš©ë²•ì€ ì•„ë˜ Linkë¥¼ ì°¸ì¡°í•´ ì£¼ì„¸ìš”

  [colorednoise Github](https://github.com/felixpatzelt/colorednoise)
  
  [Package â€˜colorednoiseâ€™](https://cran.r-project.org/web/packages/colorednoise/colorednoise.pdf)

* colorednoise Packageë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.   


```python
!pip install colorednoise 
```

    Collecting colorednoise
      Downloading colorednoise-1.1.1.tar.gz (5.2 kB)
    Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from colorednoise) (1.19.5)
    Building wheels for collected packages: colorednoise
      Building wheel for colorednoise (setup.py) ... [?25ldone
    [?25h  Created wheel for colorednoise: filename=colorednoise-1.1.1-py3-none-any.whl size=3958 sha256=65340b48a6e373c240574bcf7e108ed4683fa59c36e081904a9372abfdf57aef
      Stored in directory: /root/.cache/pip/wheels/1a/ca/93/dfd64286aef6fc206b727bd4cf2d5c17efe34d62b918c8f4a7
    Successfully built colorednoise
    Installing collected packages: colorednoise
    Successfully installed colorednoise-1.1.1
    
    
<br>
<br>
<br>

* ê¸°íƒ€ í•„ìš”í•œ Packageë¥¼ ëª¨ë‘ Loadí•©ë‹ˆë‹¤.   


```python
import librosa
import numpy as np
import csv
from tqdm.notebook import tqdm
import pickle
from skimage.transform import resize
import pandas as pd

import tensorflow as tf

import librosa.display
import colorednoise as cn

from sklearn.model_selection import StratifiedKFold

from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout,GlobalAveragePooling2D,BatchNormalization
from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
```

   

   

   

* ì´ ë¬¸ì„œëŠ” Kaggle Notebookì—ì„œ ë§Œë“¤ì–´ì„œ ì•„ë˜ í•­ëª©ì€ ìë™ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë‚´ìš©ì´ë‹ˆ ê·¸ëƒ¥ ì°¸ê³ ë§Œ í•´ì£¼ì„¸ìš”.   


```python
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        #print(os.path.join(dirname, filename))
        pass

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
```


<br>
<br>
<br>
<br>

* ì•„ë˜ ë‚´ìš©ë“¤ì€ Sound Augmentation ê´€ë ¨ ë‚´ìš©ë“¤ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¨ ê²ƒì…ë‹ˆë‹¤.   


```python
class AudioTransform:
    def __init__(self, always_apply=False, p=0.5):
        self.always_apply = always_apply
        self.p = p

    def __call__(self, y: np.ndarray):
        if self.always_apply:
            return self.apply(y)
        else:
            if np.random.rand() < self.p:
                return self.apply(y)
            else:
                return y

    def apply(self, y: np.ndarray):
        raise NotImplementedError


class Compose:
    def __init__(self, transforms: list):
        self.transforms = transforms

    def __call__(self, y: np.ndarray):
        for trns in self.transforms:
            y = trns(y)
        return y


class OneOf:
    def __init__(self, transforms: list):
        self.transforms = transforms

    def __call__(self, y: np.ndarray):
        n_trns = len(self.transforms)
        trns_idx = np.random.choice(n_trns)
        trns = self.transforms[trns_idx]
        return trns(y)
```

<br>
<br>

#### 1.1. GaussianNoiseSNR


```python
class GaussianNoiseSNR(AudioTransform):
    def __init__(self, always_apply=False, p=0.5, min_snr=5.0, max_snr=20.0, **kwargs):
        super().__init__(always_apply, p)

        self.min_snr = min_snr
        self.max_snr = max_snr

    def apply(self, y: np.ndarray, **params):
        snr = np.random.uniform(self.min_snr, self.max_snr)
        a_signal = np.sqrt(y ** 2).max()
        a_noise = a_signal / (10 ** (snr / 20))

        white_noise = np.random.randn(len(y))
        a_white = np.sqrt(white_noise ** 2).max()
        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)
        return augmented
```

<br>
<br>

#### 1.2.  PinkNoiseSNR


```python
class PinkNoiseSNR(AudioTransform):
    def __init__(self, always_apply=False, p=0.5, min_snr=5.0, max_snr=20.0, **kwargs):
        super().__init__(always_apply, p)

        self.min_snr = min_snr
        self.max_snr = max_snr

    def apply(self, y: np.ndarray, **params):
        snr = np.random.uniform(self.min_snr, self.max_snr)
        a_signal = np.sqrt(y ** 2).max()
        a_noise = a_signal / (10 ** (snr / 20))

        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))
        a_pink = np.sqrt(pink_noise ** 2).max()
        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)
        return augmented        
```

<br>
<br>

#### 1.3. PitchShift


```python
class PitchShift(AudioTransform):
    def __init__(self, always_apply=False, p=0.5, max_steps=5, sr=32000):
        super().__init__(always_apply, p)

        self.max_steps = max_steps
        self.sr = sr

    def apply(self, y: np.ndarray, **params):
        n_steps = np.random.randint(-self.max_steps, self.max_steps)
        augmented = librosa.effects.pitch_shift(y, sr=self.sr, n_steps=n_steps)
        return augmented        
```

<br>
<br>

#### 1.4. TimeShift


```python
class TimeShift(AudioTransform):
    def __init__(self, always_apply=False, p=0.5, max_shift_second=2, sr=32000, padding_mode="replace"):
        super().__init__(always_apply, p)
    
        assert padding_mode in ["replace", "zero"], "`padding_mode` must be either 'replace' or 'zero'"
        self.max_shift_second = max_shift_second
        self.sr = sr
        self.padding_mode = padding_mode

    def apply(self, y: np.ndarray, **params):
        shift = np.random.randint(-self.sr * self.max_shift_second, self.sr * self.max_shift_second)
        augmented = np.roll(y, shift)
        if self.padding_mode == "zero":
            if shift > 0:
                augmented[:shift] = 0
            else:
                augmented[shift:] = 0
        return augmented
```

<br>
<br>

#### 1.5. TimeShift


```python
class VolumeControl(AudioTransform):
    def __init__(self, always_apply=False, p=0.5, db_limit=10, mode="uniform"):
        super().__init__(always_apply, p)

        assert mode in ["uniform", "fade", "fade", "cosine", "sine"], \
            "`mode` must be one of 'uniform', 'fade', 'cosine', 'sine'"

        self.db_limit= db_limit
        self.mode = mode

    def apply(self, y: np.ndarray, **params):
        db = np.random.uniform(-self.db_limit, self.db_limit)
        if self.mode == "uniform":
            db_translated = 10 ** (db / 20)
        elif self.mode == "fade":
            lin = np.arange(len(y))[::-1] / (len(y) - 1)
            db_translated = 10 ** (db * lin / 20)
        elif self.mode == "cosine":
            cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)
            db_translated = 10 ** (db * cosine / 20)
        else:
            sine = np.sin(np.arange(len(y)) / len(y) * np.pi * 2)
            db_translated = 10 ** (db * sine / 20)
        augmented = y * db_translated
        return augmented        
```


<br>
<br>
<br>
<br>

* ì•„ë˜ ìƒìˆ˜ë“¤ì€ ì´ì „ Revisionê³¼ ê±°ì˜ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ì§€ë§Œ, Sound Fileì„ Cropí•˜ëŠ” ê¸¸ì´ë¥¼ 6ì´ˆì—ì„œ 10ì´ˆë¡œ ëŠ˜ë ¸ìŠµë‹ˆë‹¤.   


```python
SLICE_TIME_WINDOWS = 10

fft = 2048
hop = 512

# Less rounding errors this way
sr = 48000
length = SLICE_TIME_WINDOWS * sr

F_MIN = 84
F_MAX = 15056

NUM_CLASS = 24
```

<br>
<br>
<br>
<br>

* ìœ„ì—ì„œ ì •ì˜í•œ ë‹¤ì–‘í•œ Sound Augmentation ê¸°ë²•ë“¤ì„ Randomí•˜ê²Œ ì ìš©í•˜ë„ë¡ í•´ì¤ë‹ˆë‹¤.   


```python
transform = Compose([
  OneOf([
      GaussianNoiseSNR(always_apply=True, min_snr=5, max_snr=20),
      PinkNoiseSNR(always_apply=True, min_snr=5.0, max_snr=20.0)
  ]),
    PitchShift(always_apply=True, max_steps=5, sr=sr),
    TimeShift(always_apply=True, max_shift_second=4, sr=sr),
    VolumeControl(always_apply=True, mode="sine")
])
```

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

### 2. Custom Generator

* ì´ì „ Post [Custom Generator](https://moonlight314.github.io/deeplearning/Custom_Generator/)ì—ì„œ ë‹¤ë£¨ì—ˆë˜ ì‚¬í•­ë“¤ì„ ì´ë²ˆì— ì ìš©í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


* ì´ë²ˆì—ëŠ” Trainì— ì‚¬ìš©í•  Generatorì™€ Validationì—ì„œ ì‚¬ìš©í•  Generatorë¥¼ ë”°ë¡œ ë§Œë“¤ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


* ë‘ Generatorì˜ ì°¨ì´ì ì€ **Augmentationì„ ì ìš©í•˜ëŠëƒ í•˜ì§€ ì•ŠëŠëƒì˜ ì°¨ì´**ë§Œ ìˆì„ ë¿ ë‹¤ë¥¸ ì°¨ì´ëŠ” ì—†ìŠµë‹ˆë‹¤.


* ì¼ë°˜ì ìœ¼ë¡œ Validation Datasetì—ëŠ” Augmentationì„ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.


* 'train_gen' optionì´ Trainê³¼ Validationì„ êµ¬ë¶„í•˜ëŠ” Parameterì…ë‹ˆë‹¤. 

   


```python
class DataGenerator(tf.keras.utils.Sequence):
    
    'Generates data for Keras'
    def __init__(self, 
                 list_IDs, 
                 labels, 
                 batch_size=32, 
                 dim=(128,563), 
                 n_channels=1,
                 t_min=[],
                 t_max=[],
                 recording_id=[],
                 train=True,
                 n_classes=24, 
                 shuffle=True):
        
        'Initialization'
        self.dim = dim
        self.batch_size = batch_size
        self.labels = labels
        self.list_IDs = list_IDs
        self.n_channels = n_channels
        self.t_min = t_min
        self.t_max = t_max
        self.recording_id = recording_id
        self.n_classes = n_classes
        self.train_gen = train
        self.shuffle = shuffle
        
        self.n = 0
        self.max = self.__len__()

        self.on_epoch_end()
        

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(list_IDs_temp)

        return X, y

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)
            
    
    def __next__(self):
        if self.n >= self.max:
           self.n = 0
        result = self.__getitem__(self.n)
        self.n += 1
        return result
    

    def __data_generation(self, list_IDs_temp):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.empty((self.batch_size, *self.dim, self.n_channels))
        y = np.empty((self.batch_size), dtype=int)

        
        # Generate data
        for i, ID in enumerate(list_IDs_temp):
            # Store sample
            wav, sr = librosa.load('/kaggle/input/rfcx-species-audio-detection/train/' + recording_id[ID] + '.flac', sr=None)

            t_start = self.t_min[ID] * sr
            t_end = self.t_max[ID] * sr
            
            # Positioning sound slice
            center = np.round((t_start + t_end) / 2)
            beginning = center - length / 2
            
            if beginning < 0:
                beginning = 0                
            
            ending = beginning + length
            
            if ending > len(wav):
                ending = len(wav)
                beginning = ending - length
            
            slice = wav[int(beginning):int(ending)]

            if self.train_gen == True:
                aug_slice = transform( slice )
            else:
                aug_slice = slice
                
        
            mel_spec = librosa.feature.melspectrogram(aug_slice, n_fft=fft, hop_length=hop, sr=sr, fmin=F_MIN, fmax=F_MAX, power=2)    
            mel_spec = librosa.core.amplitude_to_db(np.abs(mel_spec))

            mel_spec = mel_spec - np.min(mel_spec)
            mel_spec = mel_spec / np.max(mel_spec)   
            
            stacked = resize(mel_spec , (self.dim[0], self.dim[1], self.n_channels))
            X[i,] = stacked

            
            # Store class
            y[i] = self.labels[ID]
        
        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)
```


<br>
<br>
<br>
<br>

* ì´ì „ ë°©ë²•ê³¼ ìœ ì‚¬í•˜ê²Œ ì§„í–‰í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


* train_tp.csvì—ì„œ Train Data ê´€ë ¨ Meta ì •ë³´ë¥¼ ì½ì–´ì„œ ì¤€ë¹„í•©ë‹ˆë‹¤.


```python
data = pd.read_csv("/kaggle/input/rfcx-species-audio-detection/train_tp.csv")
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>recording_id</th>
      <th>species_id</th>
      <th>songtype_id</th>
      <th>t_min</th>
      <th>f_min</th>
      <th>t_max</th>
      <th>f_max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>003bec244</td>
      <td>14</td>
      <td>1</td>
      <td>44.5440</td>
      <td>2531.250</td>
      <td>45.1307</td>
      <td>5531.25</td>
    </tr>
    <tr>
      <th>1</th>
      <td>006ab765f</td>
      <td>23</td>
      <td>1</td>
      <td>39.9615</td>
      <td>7235.160</td>
      <td>46.0452</td>
      <td>11283.40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>007f87ba2</td>
      <td>12</td>
      <td>1</td>
      <td>39.1360</td>
      <td>562.500</td>
      <td>42.2720</td>
      <td>3281.25</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0099c367b</td>
      <td>17</td>
      <td>4</td>
      <td>51.4206</td>
      <td>1464.260</td>
      <td>55.1996</td>
      <td>4565.04</td>
    </tr>
    <tr>
      <th>4</th>
      <td>009b760e6</td>
      <td>10</td>
      <td>1</td>
      <td>50.0854</td>
      <td>947.461</td>
      <td>52.5293</td>
      <td>10852.70</td>
    </tr>
  </tbody>
</table>
</div>


